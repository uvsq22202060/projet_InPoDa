{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json                         # module pour load le file\n",
    "import re                           # module pour retourner les hasthtags\n",
    "from textblob import TextBlob       # module pour analyser le sentiment du tweet\n",
    "import pandas as pd                 # module pour visualiser et comparer les tweets\n",
    "import matplotlib.pyplot as plt     \n",
    "from datetime import datetime\n",
    "import random as rd             \n",
    "import langid\n",
    "\n",
    "# Data utilisé pour la création des dictionnaires pour faciliter l'analyse de diagramme,...\n",
    "file = open(\"tweets.json\",\"r\")\n",
    "data =json.load(file)\n",
    "file.close()\n",
    "\n",
    "# Data utilisé pour analyser visuellement les différentes caractéristiques d'un tweet\n",
    "data2 = pd.read_json(\"tweets.json\")\n",
    "df_data = pd.DataFrame(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tweet :\n",
    "    def __init__(self,id_tweet,location_tweet,creation_tweet,retweet_count,tweet_language,tweet_text) :\n",
    "        self.id = id_tweet\n",
    "        self.location = location_tweet\n",
    "        self.created = creation_tweet\n",
    "        self.retweet = retweet_count\n",
    "        self.language = tweet_language\n",
    "        self.text = tweet_text\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"Tweet id : {self.id}\\nAuthor Location : {self.location} \\nTweet Creation : {self.created} \\nNumber of Retweets : {self.retweet} \\nTweet Language : {self.language} \\nTweet Text : {self.text}\"\n",
    "    \n",
    "    def get_author(self):\n",
    "        id_tweet = self.id\n",
    "        return id_tweet\n",
    "    \n",
    "    def get_text(self):\n",
    "        return self.text\n",
    "    \n",
    "    def get_hashtags(self):\n",
    "        return re.findall(r\"#(\\w+)\", self.text)\n",
    "\n",
    "    def get_mention(self):\n",
    "        return re.findall(r\"@(\\w+)\", self.text)\n",
    "    \n",
    "    def get_sentiment(self):\n",
    "        text = TextBlob(self.text)\n",
    "        text_polarity = text.sentiment.polarity\n",
    "        if text_polarity > 0 :\n",
    "            return \"Positive\"\n",
    "        elif text_polarity < 0 :\n",
    "            return \"Negative\"\n",
    "        else :\n",
    "            return \"Neutral\" \n",
    "\n",
    "\n",
    "#instance/ objets de la class\n",
    "tweets = [Tweet(tweet[\"id\"],tweet[\"AuthorLocation\"],tweet[\"CreatedAt\"],tweet[\"RetweetCount\"],tweet[\"TweetLanguage\"],tweet[\"TweetText\"]) for tweet in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################################################################\n",
    "##########################################  AVEC LES DICTIONNAIRES   ####################################################\n",
    "#########################################################################################################################\n",
    "\n",
    "# Pour Top K Hashtags -> 2 fonctions\n",
    "\n",
    "# La première :\n",
    "def all_hashtag():\n",
    "    '''retourne tout les hashtags du fichier json dans une liste'''\n",
    "    l = []                                         # on intialise la liste qui va être retournée à l'éxécution de la fonction\n",
    "    for tweet in tweets:                           # on parcours tout les tweets (un par un)\n",
    "        if tweet.get_hashtags()== [] :             # on vérifie avec l'atribut de l'instance si la valeur retourner est  \"[]\" <- pas de valeur ; dans ce cas là on passe au tweet suivant\n",
    "            continue\n",
    "        else :\n",
    "            temp = tweet.get_hashtags()            # on affecte a temp (variable temporaire) la liste des hashtags de chaque tweet\n",
    "            for hashtag in temp :                  # on accède à chaque hashtag présent dans temp\n",
    "                l.append(hashtag)                  # on l'affecte à la liste finale qu'on va retourner\n",
    "                \n",
    "    return l\n",
    "    \n",
    "   \n",
    "# La deuxième :\n",
    "def top_hashtag(k):\n",
    "    '''retourne le top k (index) hashtag utilisé dans la database'''\n",
    "    hashtags = all_hashtag()                       # utilisation de la fonction all_hashtag() pour récupérer la liste complète des hashtag\n",
    "    hashtag_count = {}                             # on initialise un dictionnaire vide pour compter chaque occurence de chaque hashtag\n",
    "    for hashtag in hashtags :                      # ici on prend chaque hashtag un par un, ici nommé \"e\" (pour élément)\n",
    "        if hashtag in hashtag_count :              # on vérifie si \"hashtag\" est dans le dictionnaire qui compte les occurences\n",
    "            hashtag_count[hashtag] += 1            # dans ce cas là on incrémente sa valeur de 1\n",
    "        else :\n",
    "            hashtag_count[hashtag] = 1             # dans le cas contraire, on initialise la clé \"hashtag\" à une valeur initiale de 1 \n",
    "\n",
    "    hashtag_count = dict(sorted(hashtag_count.items(),key = lambda x : x[1], reverse=True)) # on tri le dictionnaire en fonction des valeurs avec le lambda x[1] et reverse = True (de manière croissante)\n",
    "    temp = list(hashtag_count.items())[:k]        # on converti le dictionnaire en une liste pour pouvoir effectué un slicing (afin d'obtenir les top k éléments) \n",
    "    top_k_hashtag = dict(temp)                    # on reconverti en dictionnaire afin de pouvoir manipuler les clés et valeurs facilement et dans un odre précis\n",
    "    \n",
    "    # Diagramme avec plt\n",
    "    x_hashtag = list(top_k_hashtag.keys())        # on affecte à la variable x_hashtag les clés du dictionnaire (les hashtags (str))\n",
    "    y_occurence = list(top_k_hashtag.values())    # on affecte à la variable y_occurence les valeurs des clés du dictionnaire (les occurences)\n",
    "\n",
    "    plt.bar(x_hashtag,y_occurence)                # on créer le diagramme en bar avec en x -> x_hashtag et en y -> y_occurence\n",
    "    plt.xlabel(\"Hashtag\")                         # \"Hashtag\" comme titre de l'axe des x\n",
    "    plt.ylabel(\"Occurence\")                       # \"Occurence\" comme titre de l'axe des y\n",
    "\n",
    "    plt.xticks(fontsize=6)                        # on précise la taille du texte pour les valeurs en x (les hashtags)\n",
    "    plt.show()                                    # affichage du diagramme\n",
    "\n",
    "    return top_k_hashtag                          # on retourne en même temps le dictionnaire trié en ordre croissant des top k hashtags\n",
    "\n",
    "#########################################################################################################################\n",
    "\n",
    "# Pour Top K Users -> 2 fonctions \n",
    "\n",
    "# La première : \n",
    "def all_users():\n",
    "    '''retourne tout les utilisateurs présent dans le fichier json dans une liste'''\n",
    "    l = []                                       # on intialise la liste qui va être retournée à l'éxécution de la fonction\n",
    "    for tweet in tweets:                         # on parcours tout les tweets (un par un)\n",
    "        user = tweet.get_author()                # on extrait l'auteur grâce à la méthode .get_author() qu'on place dans la variable user\n",
    "        l.append(user)                           # on ajoute à la liste l'utilisateur/id du tweet\n",
    "                \n",
    "    return l\n",
    "\n",
    "# La deuxième : \n",
    "def top_users(k):\n",
    "    '''retourne le top k (index) d'utilisateurs/id présent dans la database'''\n",
    "    users = all_users()                          # utilisation de la fonction all_users() pour récupérer la liste complète des utilisateurs\n",
    "    user_ntweet = {}                             # on initialise un dictionnaire vide pour compter chaque occurence de chaque id\n",
    "    for user in users :                          # ici on prend chaque id un par un, ici nommé \"user\"\n",
    "        if user in user_ntweet :                 # on vérifie si l'id est déjà dans le dictionnaire\n",
    "            user_ntweet[user] += 1               # si c'est le ce cas, on incrémente sa valeur de 1 \n",
    "        else :\n",
    "            user_ntweet[user] = 1                # sinon on crée une clé pour l'id correspondant et on initie sa valeur à 1 \n",
    "\n",
    "    user_ntweet = dict(sorted(user_ntweet.items(), key = lambda x : x[1], reverse=True)) # on tri le dictionnaire en fonction des valeurs avec le lambda x[1] et reverse = True (de manière croissante)\n",
    "    temp = list(user_ntweet.items())[:k]         # on converti le dictionnaire en une liste pour pouvoir effectué un slicing (afin d'obtenir les top k éléments)\n",
    "    top_k_users = dict(temp)                     # on reconverti en dictionnaire afin de pouvoir manipuler les clés et valeurs facilement et dans un odre précis\n",
    "\n",
    "    x_user = list(top_k_users.keys())            # on affecte à la variable x_user les clés du dictionnaire (les id (str))\n",
    "    y_occurence = list(top_k_users.values())     # on affecte à la variable y_occurence les valeurs du dictionnaire (les occurences)\n",
    "\n",
    "    plt.bar(x_user,y_occurence)                  # on créer le diagramme en bar avec en x -> x_hashtag et en y -> y_occurence\n",
    "    plt.xlabel(\"User\")                           # \"User\" comme titre de l'axe des x\n",
    "    plt.ylabel(\"Occurence\")                      # \"Occurence\" comme titre de l'axe des y\n",
    "\n",
    "    plt.xticks(fontsize=5)                       # on précise la taille du texte pour les valeurs en x (les id)\n",
    "    plt.show()                                   # affichage du diagramme\n",
    "\n",
    "    return top_k_users                           # on retourne en même temps le dictionnaire trié en ordre croissant des top k users\n",
    "\n",
    "#########################################################################################################################\n",
    "\n",
    "# Pour the top K mentions -> 2 fonctions \n",
    "\n",
    "# La première : \n",
    "def all_mentions():\n",
    "    '''retourne toutes les mentions de la database'''\n",
    "    l = []                                        # on initialise la liste qui va être utilisée pour retourner les mentions à l'éxécution de la fonction\n",
    "    for tweet in tweets:\n",
    "        if tweet.get_mention()== [] :             # on vérifie avec l'atribut de l'instance si la valeur retourner est  \"[]\" <- pas de valeur ; dans ce cas là on passe au tweet suivant\n",
    "            continue\n",
    "        else :\n",
    "            mentions = tweet.get_mention()        # on place les mentions obtenues du tweet dans la variable temporaire mentions (qui va correspondre à une liste) \n",
    "            for mention in mentions :             # on parcours chaque élément de la liste (ils peuvent être dans une liste de liste par exemple :[[mention],mention2,...])\n",
    "                l.append(mention)                 # et on l'ajoute à notre liste finale\n",
    "                \n",
    "    return l\n",
    "\n",
    "def top_mention(k):\n",
    "    '''retourne le top k (index) d'utilisateurs/id présent dans la database'''\n",
    "    mentions = all_mentions()                       # utilisation de la fonction all_mentions() pour récupérer la liste complète des mentions\n",
    "    mention_ntweet = {}                             # on initialise un dictionnaire vide pour compter chaque occurence de chaque mention\n",
    "    for mention in mentions :                       # ici on prend chaque mention, une par une\n",
    "        if mention in mention_ntweet :              # on vérifie si la mention est présente dans le dictionnaire\n",
    "            mention_ntweet[mention] += 1            # dans ce cas là on incrémente la valeur corresponde à la mention (la clé)\n",
    "        else :\n",
    "            mention_ntweet[mention] = 1             # dans le cas contraire on initie la clé correspondante à la mention à 1\n",
    "\n",
    "    mention_ntweet = dict(sorted(mention_ntweet.items(),key = lambda x : x[1], reverse=True)) # on tri le dictionnaire en fonction des valeurs avec le lambda x[1] et reverse = True (de manière croissante)\n",
    "    temp = list(mention_ntweet.items())[:k]         # on converti le dictionnaire en une liste pour pouvoir effectué un slicing (afin d'obtenir les top k éléments)\n",
    "    top_k_mentions = dict(temp)                     # on reconverti la liste en dictionnaire trié en ordre croissant des top k mentions\n",
    "\n",
    "    x_mention = list(top_k_mentions.keys())         # on affecte à la variable x_mention les clés du dictionnaire (les mentions (str))\n",
    "    y_occurence = list(top_k_mentions.values())     # on affecte à la variable y_occurence les valeurs du dictionnaire (les occurences)\n",
    "\n",
    "    plt.bar(x_mention,y_occurence)                  # on créer le diagramme en bar avec en x -> x_mention et en y -> y_occurence\n",
    "    plt.xlabel(\"Mention\",)                          # on créer le diagramme en bar avec en x -> x_mention\n",
    "    plt.ylabel(\"Occurence\")                         # on créer le diagramme en bar avec en y -> y_occurence\n",
    "\n",
    "    plt.xticks(fontsize=7)                          # on précise la taille du texte pour les valeurs en x (les mentions)\n",
    "    plt.show()                                      # affichage du diagramme\n",
    "\n",
    "    return top_k_mentions                           # on retourne en même temps le dictionnaire trié en ordre croissant des top k mentions\n",
    "\n",
    "#########################################################################################################################\n",
    "\n",
    "def top_topics():\n",
    "    pass\n",
    "\n",
    "\n",
    "###########################################################################################################################\n",
    "################################################## AVEC LES DATAFRAMES   ##################################################\n",
    "###########################################################################################################################\n",
    "\n",
    "\n",
    "def all_tweet_mention(mention):\n",
    "    '''retourne l'ensemble des tweets mentionnant un utilisateur spécifique dans un dataframe'''                                                               \n",
    "    return df_data[df_data[\"TweetText\"].str.contains(f\"@{mention}\",regex=False)]              # on tri les lignes de la database pour extraire seulement celle qui contiennent @mention dans la colonne \n",
    "\n",
    "def all_tweet_hashtag(hashtag):\n",
    "    '''retourne l'ensemble des tweets faisant référence à un hashtag spécifique'''                                                               \n",
    "    return df_data[df_data[\"TweetText\"].str.contains(f\"#{hashtag}\",regex=False)]              # on tri les lignes de la database pour extraire seulement celle qui contiennent #hashtag dans la colonne de TweetText\n",
    "\n",
    "def user_specified_hashtag(hashtag):\n",
    "    '''retourne les id de chaque utilisateur mentionnant un hashtag spécifique'''                                                         \n",
    "    return df_data[df_data[\"TweetText\"].str.contains(f\"#{hashtag}\",regex=True)].get(\"id\")     # on tri les lignes de la database pour extraire  les #hashtag présent dans la colonne TweetText et on extrait seulement les id\n",
    "\n",
    "def user_mentionned(user):\n",
    "    '''retourne les utilisateurs mentionnés par un utilisateur spécifique'''                                                                \n",
    "    text = str(df_data[df_data[\"id\"]==user].get(\"TweetText\"))                                 # on attribue à la variable text le texte du tweet qui correspond à l'utilisiateur spécifique\n",
    "    return re.findall(r\"@(\\w+)\", text)                                                        # on nettoie le text en extrayant les mentions avec le r\"@(\\w+)\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################# PARTIE SUR LA CREATION DE TWEET #############################################################\n",
    "\n",
    "def creation_time():\n",
    "    '''retourne la date,heure, ... actuelle dans le format utilisé dans le base de donnée'''\n",
    "    actual_time = datetime.now()                                          # on attribue la date actuelle à la variable actual_time \n",
    "    actual_time = actual_time.strftime(\"%Y-%m-%dT%H:%M:%SZ\")              # on reformatise la date avec le format correspondant au fichier json, https://docs.python.org/3/library/datetime.html#strftime-strptime-behavior\n",
    "    return actual_time\n",
    "\n",
    "def random_location():\n",
    "    '''retourner une ville aléatoire pour simuler la localisation de l'auteur du tweet'''                                                    \n",
    "    locations =[                                                          # locations est une liste de ville \n",
    "                \"Tokyo, Japan\", \n",
    "                \"New York City, United-States\",\n",
    "                \"London, England\",\n",
    "                \"Pekin, China\",\n",
    "                \"Paris, France\",\n",
    "                \"Montreal, Canada\",\n",
    "                \"Madrid, Spain\",\n",
    "                \"Los Angeles, United-States\",\n",
    "                \"Delhi, India\",\n",
    "                \"Beirut, Lebanon\",\n",
    "                \"Versailles, France\",\n",
    "                \"Amsterdam, Netherland\",\n",
    "                \"Shanghai, China\",\n",
    "                \"Moscou, Russia\",\n",
    "                \"São Paulo, Brasil\"\n",
    "                ]\n",
    "    \n",
    "    return locations[rd.randint(0,len(locations)-1)]                     # on va retourner un ville aléatoire avec l'utilsation du module random (pour l'index)\n",
    "\n",
    "def create_tweet():\n",
    "    '''Fonction qui va permettre d'écrire un tweet et de l'intégrer dans la base de donnée'''  \n",
    "\n",
    "    text_tweet = input(\"Que voulez vous tweetez ?\")                      # le sujet de notre tweet est récupérer dans la variable text_tweet\n",
    "    tweet_lang,_ = langid.classify(text_tweet)                           # la langue est extraite de la variable text_tweet grace au module langid\n",
    "    tweet = {                                                            # dictionnaire qui va contenir les informations sur le tweet\n",
    "        \"id\": int(input(\"Veuillez entrez votre id: \")),                  # on récupère l'id de l'utilisateur (il va le rentrer)\n",
    "        \"AuthorLocation\": random_location(),\n",
    "        \"CreatedAt\": creation_time() ,\n",
    "        \"RetweetCount\": rd.randint(1,10),\n",
    "        \"TweetLanguage\": tweet_lang,\n",
    "        \"TweetText\": text_tweet                                          # à corriger pour les é etc on obtient /u... \n",
    "            }\n",
    "\n",
    "    try:\n",
    "        with open(\"filetest.json\", \"r\") as file:\n",
    "            database = json.load(file)\n",
    "    except FileNotFoundError:\n",
    "         \n",
    "         database = []\n",
    "\n",
    "    \n",
    "    database.append(tweet)\n",
    "\n",
    "    \n",
    "    with open(\"filetest.json\", \"w\") as file:\n",
    "        json.dump(database, file,indent=3)\n",
    "\n",
    "create_tweet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaning(text):\n",
    "  '''retourne le texte entrée, nettoyer de tout symboles/emojis'''\n",
    "  # Pattern trouvé sur le lien suivant : https://gist.github.com/Alex-Just/e86110836f3f93fe7932290526529cd1#gistcomment-3208085\n",
    "  \n",
    "  pattern = re.compile(\n",
    "    \"([\"\n",
    "    \"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "    \"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "    \"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "    \"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "    \"\\U0001F700-\\U0001F77F\"  # alchemical symbols\n",
    "    \"\\U0001F780-\\U0001F7FF\"  # Geometric Shapes Extended\n",
    "    \"\\U0001F800-\\U0001F8FF\"  # Supplemental Arrows-C\n",
    "    \"\\U0001F900-\\U0001F9FF\"  # Supplemental Symbols and Pictographs\n",
    "    \"\\U0001FA00-\\U0001FA6F\"  # Chess Symbols\n",
    "    \"\\U0001FA70-\\U0001FAFF\"  # Symbols and Pictographs Extended-A\n",
    "    \"\\U00002702-\\U000027B0\"  # Dingbats\n",
    "    \"])\"\n",
    "                      )\n",
    "  \n",
    "  text = re.sub(pattern, r'', text)                  # ici l'expression regulière va supprimer (sub en anglais) les émojis et caractères contenus dans le pattern\n",
    "  return text\n",
    "\n",
    "def transfer(source, destination):\n",
    "  '''retourne un \"fichier_atterissage.json\", une base de donnée nettoyer'''\n",
    "  with open(source,\"r\") as source_file, open(destination,\"w\") as destination_file :       # on ouvre le fichier source (-> source_file) et fichier destination (-> destination_file)\n",
    "\n",
    "      content_source = source_file.read()                        # on extrait le contenu de notre fichier source que l'on attribue à la variable content_source\n",
    "      content_source = text_cleaning(content_source)             # \n",
    "\n",
    "      destination_file.write(content_source)\n",
    "\n",
    "transfer(\"tweets.json\",\"fichier_atterrissage.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################## TESTS ########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_hashtag()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tweet_hashtag(\"ArtificialIntelligence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_mentionned(1418705513660010496)        # à corriger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tweet_hashtag(\"MachineLearning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tweet_mention(\"nigewillson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_mentionned(1415291886860967936)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_hashtag(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test for Top k hashtags\n",
    "all_hashtag()\n",
    "top_hashtag(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test for Top k users\n",
    "all_users()\n",
    "top_users(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test for Top k mentions\n",
    "all_mentions()\n",
    "top_mention(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>AuthorLocation</th>\n",
       "      <th>CreatedAt</th>\n",
       "      <th>RetweetCount</th>\n",
       "      <th>TweetLanguage</th>\n",
       "      <th>TweetText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1415291968700264448</td>\n",
       "      <td>Internet</td>\n",
       "      <td>2021-07-14T12:47:54Z</td>\n",
       "      <td>20</td>\n",
       "      <td>en</td>\n",
       "      <td>RT @HarbRimah: Making AI Sing https://t.co/FJo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1415594177136668672</td>\n",
       "      <td>The Netherlands</td>\n",
       "      <td>2021-07-15T08:48:46Z</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>Employers turning to #ArtificialIntelligence t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>1415775469161652224</td>\n",
       "      <td>Europe</td>\n",
       "      <td>2021-07-15T20:49:10Z</td>\n",
       "      <td>37</td>\n",
       "      <td>en</td>\n",
       "      <td>RT @Paula_Piccard: Decoding crop genetics with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>1416122729066123264</td>\n",
       "      <td>The Netherlands</td>\n",
       "      <td>2021-07-16T19:49:03Z</td>\n",
       "      <td>1</td>\n",
       "      <td>en</td>\n",
       "      <td>A simple model of the brain provides new direc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>1416168124831895552</td>\n",
       "      <td>Germany</td>\n",
       "      <td>2021-07-16T22:49:26Z</td>\n",
       "      <td>167</td>\n",
       "      <td>en</td>\n",
       "      <td>RT @Paula_Piccard: 9 top applications of artif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>1416364411355385856</td>\n",
       "      <td>Brighton &amp; Hove, UK</td>\n",
       "      <td>2021-07-17T11:49:25Z</td>\n",
       "      <td>4</td>\n",
       "      <td>en</td>\n",
       "      <td>RT @Fisher85M: What are some Artificial Intell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>1416515546753929216</td>\n",
       "      <td>Tallinn, Estonia</td>\n",
       "      <td>2021-07-17T21:49:58Z</td>\n",
       "      <td>307</td>\n",
       "      <td>en</td>\n",
       "      <td>RT @Paula_Piccard: Artificial Intelligence Cre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>1416515488000221184</td>\n",
       "      <td>Internet</td>\n",
       "      <td>2021-07-17T21:49:44Z</td>\n",
       "      <td>307</td>\n",
       "      <td>en</td>\n",
       "      <td>RT @Paula_Piccard: Artificial Intelligence Cre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>1416681648662269952</td>\n",
       "      <td></td>\n",
       "      <td>2021-07-18T08:50:00Z</td>\n",
       "      <td>79</td>\n",
       "      <td>en</td>\n",
       "      <td>RT @machinelearnTec: Using artificial intellig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>1416681626311008256</td>\n",
       "      <td>Europe</td>\n",
       "      <td>2021-07-18T08:49:55Z</td>\n",
       "      <td>79</td>\n",
       "      <td>en</td>\n",
       "      <td>RT @machinelearnTec: Using artificial intellig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>1417225356122066944</td>\n",
       "      <td>Germany</td>\n",
       "      <td>2021-07-19T20:50:30Z</td>\n",
       "      <td>201</td>\n",
       "      <td>en</td>\n",
       "      <td>RT @Indika_AI: Here's everything you need to k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>1417225332822847488</td>\n",
       "      <td>Europe</td>\n",
       "      <td>2021-07-19T20:50:24Z</td>\n",
       "      <td>201</td>\n",
       "      <td>en</td>\n",
       "      <td>RT @Indika_AI: Here's everything you need to k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>1417376425003335680</td>\n",
       "      <td></td>\n",
       "      <td>2021-07-20T06:50:47Z</td>\n",
       "      <td>36</td>\n",
       "      <td>en</td>\n",
       "      <td>RT @FreeCodeCoupon2: #ArtificialIntelligence M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>790</th>\n",
       "      <td>1418071193077288960</td>\n",
       "      <td>Internet</td>\n",
       "      <td>2021-07-22T04:51:33Z</td>\n",
       "      <td>179</td>\n",
       "      <td>en</td>\n",
       "      <td>RT @sh_hameed: Screening for dementia with art...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>1418086201697792000</td>\n",
       "      <td></td>\n",
       "      <td>2021-07-22T05:51:11Z</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>Join us for a stimulating interaction with Dr....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>1418116397444571136</td>\n",
       "      <td>Social Media</td>\n",
       "      <td>2021-07-22T07:51:11Z</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>We live in a world of technology dichotomy; wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>838</th>\n",
       "      <td>1418252410921930752</td>\n",
       "      <td>Mexico D.F.</td>\n",
       "      <td>2021-07-22T16:51:39Z</td>\n",
       "      <td>284</td>\n",
       "      <td>en</td>\n",
       "      <td>RT @ALSALHAN: Managing Artificial Intelligence...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>851</th>\n",
       "      <td>1418297732985466880</td>\n",
       "      <td>Internet</td>\n",
       "      <td>2021-07-22T19:51:44Z</td>\n",
       "      <td>151</td>\n",
       "      <td>en</td>\n",
       "      <td>RT @Paula_Piccard: Artificial Intelligence Ide...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>1418358081340297216</td>\n",
       "      <td></td>\n",
       "      <td>2021-07-22T23:51:33Z</td>\n",
       "      <td>92</td>\n",
       "      <td>en</td>\n",
       "      <td>RT @WajdiAlkayal: Ai Vs Ml – What’s The Differ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>1418433685033037824</td>\n",
       "      <td>Europe</td>\n",
       "      <td>2021-07-23T04:51:58Z</td>\n",
       "      <td>37</td>\n",
       "      <td>en</td>\n",
       "      <td>RT @gp_pulipaka: Best AI (Artificial Intellige...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>1418448761953521664</td>\n",
       "      <td>Cimahi,West Java</td>\n",
       "      <td>2021-07-23T05:51:53Z</td>\n",
       "      <td>47</td>\n",
       "      <td>en</td>\n",
       "      <td>RT @gp_pulipaka: Best AI (Artificial Intellige...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941</th>\n",
       "      <td>1418599799046037504</td>\n",
       "      <td>India</td>\n",
       "      <td>2021-07-23T15:52:03Z</td>\n",
       "      <td>118</td>\n",
       "      <td>en</td>\n",
       "      <td>RT @kunaldchowdhury: Language as a key to arti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>942</th>\n",
       "      <td>1418599843119857664</td>\n",
       "      <td></td>\n",
       "      <td>2021-07-23T15:52:13Z</td>\n",
       "      <td>118</td>\n",
       "      <td>en</td>\n",
       "      <td>RT @kunaldchowdhury: Language as a key to arti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>1418750739179053056</td>\n",
       "      <td>Dhaka, Bangladesh</td>\n",
       "      <td>2021-07-24T01:51:49Z</td>\n",
       "      <td>209</td>\n",
       "      <td>en</td>\n",
       "      <td>RT @leads_connect: Artificial Intelligence Get...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1012</th>\n",
       "      <td>1418856414169243648</td>\n",
       "      <td></td>\n",
       "      <td>2021-07-24T08:51:44Z</td>\n",
       "      <td>53</td>\n",
       "      <td>en</td>\n",
       "      <td>RT @Paula_Piccard: Where Is the ROI in Artific...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1043</th>\n",
       "      <td>1418962214564814848</td>\n",
       "      <td></td>\n",
       "      <td>2021-07-24T15:52:09Z</td>\n",
       "      <td>102</td>\n",
       "      <td>en</td>\n",
       "      <td>RT @gp_pulipaka: Best AI (Artificial Intellige...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1113</th>\n",
       "      <td>1419203846660833280</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>2021-07-25T07:52:19Z</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>How #ArtificialIntelligence (#AI) Is Helping M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1117</th>\n",
       "      <td>1419219038073499648</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>2021-07-25T08:52:41Z</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>What Are The Three Domains of #ArtificialIntel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1128</th>\n",
       "      <td>1419264240557363200</td>\n",
       "      <td></td>\n",
       "      <td>2021-07-25T11:52:18Z</td>\n",
       "      <td>26</td>\n",
       "      <td>en</td>\n",
       "      <td>RT @bigdataconf: DEMOCRATIZATION OF #ARTIFICIA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1129</th>\n",
       "      <td>1419264263999299584</td>\n",
       "      <td>World</td>\n",
       "      <td>2021-07-25T11:52:23Z</td>\n",
       "      <td>26</td>\n",
       "      <td>en</td>\n",
       "      <td>RT @bigdataconf: DEMOCRATIZATION OF #ARTIFICIA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1137</th>\n",
       "      <td>1419294458995044352</td>\n",
       "      <td>Chennai, Tamil Nadu</td>\n",
       "      <td>2021-07-25T13:52:22Z</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>Extending Human Lifespans: Using Artificial In...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1203</th>\n",
       "      <td>1419566356966543360</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>2021-07-26T07:52:48Z</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>Using #AI to Find Bias in AI.\\nby @CadeMetz @n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1227</th>\n",
       "      <td>1419656952515158016</td>\n",
       "      <td>Bangalore, India</td>\n",
       "      <td>2021-07-26T13:52:48Z</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>Does Your Project Need Artificial Intelligence...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1257</th>\n",
       "      <td>1419792723863818240</td>\n",
       "      <td>London, England</td>\n",
       "      <td>2021-07-26T22:52:18Z</td>\n",
       "      <td>29</td>\n",
       "      <td>en</td>\n",
       "      <td>RT @Paula_Piccard: How Artificial Intelligence...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1292</th>\n",
       "      <td>1419928708824059904</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>2021-07-27T07:52:39Z</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>The Psychological And Cultural Impact Of #Arti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1294</th>\n",
       "      <td>1419959065669771264</td>\n",
       "      <td>Jammu And Kashmir</td>\n",
       "      <td>2021-07-27T09:53:17Z</td>\n",
       "      <td>4</td>\n",
       "      <td>en</td>\n",
       "      <td>RT @IainLJBrown: Artificial intelligence makes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306</th>\n",
       "      <td>1420019439605624832</td>\n",
       "      <td>::1</td>\n",
       "      <td>2021-07-27T13:53:11Z</td>\n",
       "      <td>27</td>\n",
       "      <td>en</td>\n",
       "      <td>RT @IainLJBrown: Artificial intelligence makes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1321</th>\n",
       "      <td>1420079829085343744</td>\n",
       "      <td></td>\n",
       "      <td>2021-07-27T17:53:09Z</td>\n",
       "      <td>34</td>\n",
       "      <td>en</td>\n",
       "      <td>RT @IainLJBrown: Artificial intelligence makes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1322</th>\n",
       "      <td>1420079847674716160</td>\n",
       "      <td>Kyiv, Ukraine</td>\n",
       "      <td>2021-07-27T17:53:14Z</td>\n",
       "      <td>53</td>\n",
       "      <td>en</td>\n",
       "      <td>RT @Paula_Piccard: How Artificial Intelligence...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1341</th>\n",
       "      <td>1420155283439951872</td>\n",
       "      <td>World</td>\n",
       "      <td>2021-07-27T22:52:59Z</td>\n",
       "      <td>38</td>\n",
       "      <td>en</td>\n",
       "      <td>RT @IainLJBrown: Artificial intelligence makes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1397</th>\n",
       "      <td>1420397083090116608</td>\n",
       "      <td>Marlow</td>\n",
       "      <td>2021-07-28T14:53:48Z</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>Pentagon eyes artificial intelligence (AI) ena...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1434</th>\n",
       "      <td>1420517766575034368</td>\n",
       "      <td>Rio de janeiro</td>\n",
       "      <td>2021-07-28T22:53:22Z</td>\n",
       "      <td>44</td>\n",
       "      <td>en</td>\n",
       "      <td>RT @IainLJBrown: Artificial intelligence could...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>1420578203198963712</td>\n",
       "      <td>Hounslow, London</td>\n",
       "      <td>2021-07-29T02:53:31Z</td>\n",
       "      <td>147</td>\n",
       "      <td>en</td>\n",
       "      <td>RT @WajdiAlkayal: Ai Vs Ml – What’s The Differ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1486</th>\n",
       "      <td>1420683919813275648</td>\n",
       "      <td>Mysore  and  BERLIN</td>\n",
       "      <td>2021-07-29T09:53:36Z</td>\n",
       "      <td>10</td>\n",
       "      <td>en</td>\n",
       "      <td>RT @d4hio: RT @Terralogic_: Four Predictions F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1487</th>\n",
       "      <td>1420683942844276736</td>\n",
       "      <td></td>\n",
       "      <td>2021-07-29T09:53:41Z</td>\n",
       "      <td>10</td>\n",
       "      <td>en</td>\n",
       "      <td>RT @d4hio: RT @Terralogic_: Four Predictions F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1489</th>\n",
       "      <td>1420684002365739008</td>\n",
       "      <td></td>\n",
       "      <td>2021-07-29T09:53:55Z</td>\n",
       "      <td>10</td>\n",
       "      <td>en</td>\n",
       "      <td>RT @d4hio: RT @Terralogic_: Four Predictions F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1524</th>\n",
       "      <td>1420804797612048384</td>\n",
       "      <td></td>\n",
       "      <td>2021-07-29T17:53:55Z</td>\n",
       "      <td>74</td>\n",
       "      <td>en</td>\n",
       "      <td>RT @Paula_Piccard: What Are The Three Domains ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1578</th>\n",
       "      <td>1420985919679520768</td>\n",
       "      <td>Dhaka, Bangladesh</td>\n",
       "      <td>2021-07-30T05:53:38Z</td>\n",
       "      <td>12</td>\n",
       "      <td>en</td>\n",
       "      <td>RT @gp_pulipaka: Best AI (Artificial Intellige...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1590</th>\n",
       "      <td>1421016101278916608</td>\n",
       "      <td>London, England</td>\n",
       "      <td>2021-07-30T07:53:34Z</td>\n",
       "      <td>2</td>\n",
       "      <td>en</td>\n",
       "      <td>RT @odsc: Think, fight, feel: how video game a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1602</th>\n",
       "      <td>1421076571373330432</td>\n",
       "      <td>Earth</td>\n",
       "      <td>2021-07-30T11:53:51Z</td>\n",
       "      <td>188</td>\n",
       "      <td>en</td>\n",
       "      <td>RT @TACHOUHONER: Language as a key to artifici...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id       AuthorLocation             CreatedAt  \\\n",
       "3     1415291968700264448             Internet  2021-07-14T12:47:54Z   \n",
       "99    1415594177136668672      The Netherlands  2021-07-15T08:48:46Z   \n",
       "154   1415775469161652224               Europe  2021-07-15T20:49:10Z   \n",
       "253   1416122729066123264      The Netherlands  2021-07-16T19:49:03Z   \n",
       "270   1416168124831895552             Germany   2021-07-16T22:49:26Z   \n",
       "328   1416364411355385856  Brighton & Hove, UK  2021-07-17T11:49:25Z   \n",
       "375   1416515546753929216     Tallinn, Estonia  2021-07-17T21:49:58Z   \n",
       "377   1416515488000221184             Internet  2021-07-17T21:49:44Z   \n",
       "423   1416681648662269952                       2021-07-18T08:50:00Z   \n",
       "424   1416681626311008256               Europe  2021-07-18T08:49:55Z   \n",
       "559   1417225356122066944             Germany   2021-07-19T20:50:30Z   \n",
       "561   1417225332822847488               Europe  2021-07-19T20:50:24Z   \n",
       "592   1417376425003335680                       2021-07-20T06:50:47Z   \n",
       "790   1418071193077288960             Internet  2021-07-22T04:51:33Z   \n",
       "792   1418086201697792000                       2021-07-22T05:51:11Z   \n",
       "797   1418116397444571136         Social Media  2021-07-22T07:51:11Z   \n",
       "838   1418252410921930752          Mexico D.F.  2021-07-22T16:51:39Z   \n",
       "851   1418297732985466880             Internet  2021-07-22T19:51:44Z   \n",
       "871   1418358081340297216                       2021-07-22T23:51:33Z   \n",
       "892   1418433685033037824               Europe  2021-07-23T04:51:58Z   \n",
       "896   1418448761953521664     Cimahi,West Java  2021-07-23T05:51:53Z   \n",
       "941   1418599799046037504                India  2021-07-23T15:52:03Z   \n",
       "942   1418599843119857664                       2021-07-23T15:52:13Z   \n",
       "983   1418750739179053056    Dhaka, Bangladesh  2021-07-24T01:51:49Z   \n",
       "1012  1418856414169243648                       2021-07-24T08:51:44Z   \n",
       "1043  1418962214564814848                       2021-07-24T15:52:09Z   \n",
       "1113  1419203846660833280            New Delhi  2021-07-25T07:52:19Z   \n",
       "1117  1419219038073499648            New Delhi  2021-07-25T08:52:41Z   \n",
       "1128  1419264240557363200                       2021-07-25T11:52:18Z   \n",
       "1129  1419264263999299584                World  2021-07-25T11:52:23Z   \n",
       "1137  1419294458995044352  Chennai, Tamil Nadu  2021-07-25T13:52:22Z   \n",
       "1203  1419566356966543360            New Delhi  2021-07-26T07:52:48Z   \n",
       "1227  1419656952515158016     Bangalore, India  2021-07-26T13:52:48Z   \n",
       "1257  1419792723863818240      London, England  2021-07-26T22:52:18Z   \n",
       "1292  1419928708824059904            New Delhi  2021-07-27T07:52:39Z   \n",
       "1294  1419959065669771264    Jammu And Kashmir  2021-07-27T09:53:17Z   \n",
       "1306  1420019439605624832                  ::1  2021-07-27T13:53:11Z   \n",
       "1321  1420079829085343744                       2021-07-27T17:53:09Z   \n",
       "1322  1420079847674716160        Kyiv, Ukraine  2021-07-27T17:53:14Z   \n",
       "1341  1420155283439951872                World  2021-07-27T22:52:59Z   \n",
       "1397  1420397083090116608               Marlow  2021-07-28T14:53:48Z   \n",
       "1434  1420517766575034368       Rio de janeiro  2021-07-28T22:53:22Z   \n",
       "1455  1420578203198963712     Hounslow, London  2021-07-29T02:53:31Z   \n",
       "1486  1420683919813275648  Mysore  and  BERLIN  2021-07-29T09:53:36Z   \n",
       "1487  1420683942844276736                       2021-07-29T09:53:41Z   \n",
       "1489  1420684002365739008                       2021-07-29T09:53:55Z   \n",
       "1524  1420804797612048384                       2021-07-29T17:53:55Z   \n",
       "1578  1420985919679520768    Dhaka, Bangladesh  2021-07-30T05:53:38Z   \n",
       "1590  1421016101278916608      London, England  2021-07-30T07:53:34Z   \n",
       "1602  1421076571373330432               Earth   2021-07-30T11:53:51Z   \n",
       "\n",
       "      RetweetCount TweetLanguage  \\\n",
       "3               20            en   \n",
       "99               0            en   \n",
       "154             37            en   \n",
       "253              1            en   \n",
       "270            167            en   \n",
       "328              4            en   \n",
       "375            307            en   \n",
       "377            307            en   \n",
       "423             79            en   \n",
       "424             79            en   \n",
       "559            201            en   \n",
       "561            201            en   \n",
       "592             36            en   \n",
       "790            179            en   \n",
       "792              0            en   \n",
       "797              0            en   \n",
       "838            284            en   \n",
       "851            151            en   \n",
       "871             92            en   \n",
       "892             37            en   \n",
       "896             47            en   \n",
       "941            118            en   \n",
       "942            118            en   \n",
       "983            209            en   \n",
       "1012            53            en   \n",
       "1043           102            en   \n",
       "1113             0            en   \n",
       "1117             0            en   \n",
       "1128            26            en   \n",
       "1129            26            en   \n",
       "1137             0            en   \n",
       "1203             0            en   \n",
       "1227             0            en   \n",
       "1257            29            en   \n",
       "1292             0            en   \n",
       "1294             4            en   \n",
       "1306            27            en   \n",
       "1321            34            en   \n",
       "1322            53            en   \n",
       "1341            38            en   \n",
       "1397             0            en   \n",
       "1434            44            en   \n",
       "1455           147            en   \n",
       "1486            10            en   \n",
       "1487            10            en   \n",
       "1489            10            en   \n",
       "1524            74            en   \n",
       "1578            12            en   \n",
       "1590             2            en   \n",
       "1602           188            en   \n",
       "\n",
       "                                              TweetText  \n",
       "3     RT @HarbRimah: Making AI Sing https://t.co/FJo...  \n",
       "99    Employers turning to #ArtificialIntelligence t...  \n",
       "154   RT @Paula_Piccard: Decoding crop genetics with...  \n",
       "253   A simple model of the brain provides new direc...  \n",
       "270   RT @Paula_Piccard: 9 top applications of artif...  \n",
       "328   RT @Fisher85M: What are some Artificial Intell...  \n",
       "375   RT @Paula_Piccard: Artificial Intelligence Cre...  \n",
       "377   RT @Paula_Piccard: Artificial Intelligence Cre...  \n",
       "423   RT @machinelearnTec: Using artificial intellig...  \n",
       "424   RT @machinelearnTec: Using artificial intellig...  \n",
       "559   RT @Indika_AI: Here's everything you need to k...  \n",
       "561   RT @Indika_AI: Here's everything you need to k...  \n",
       "592   RT @FreeCodeCoupon2: #ArtificialIntelligence M...  \n",
       "790   RT @sh_hameed: Screening for dementia with art...  \n",
       "792   Join us for a stimulating interaction with Dr....  \n",
       "797   We live in a world of technology dichotomy; wh...  \n",
       "838   RT @ALSALHAN: Managing Artificial Intelligence...  \n",
       "851   RT @Paula_Piccard: Artificial Intelligence Ide...  \n",
       "871   RT @WajdiAlkayal: Ai Vs Ml – What’s The Differ...  \n",
       "892   RT @gp_pulipaka: Best AI (Artificial Intellige...  \n",
       "896   RT @gp_pulipaka: Best AI (Artificial Intellige...  \n",
       "941   RT @kunaldchowdhury: Language as a key to arti...  \n",
       "942   RT @kunaldchowdhury: Language as a key to arti...  \n",
       "983   RT @leads_connect: Artificial Intelligence Get...  \n",
       "1012  RT @Paula_Piccard: Where Is the ROI in Artific...  \n",
       "1043  RT @gp_pulipaka: Best AI (Artificial Intellige...  \n",
       "1113  How #ArtificialIntelligence (#AI) Is Helping M...  \n",
       "1117  What Are The Three Domains of #ArtificialIntel...  \n",
       "1128  RT @bigdataconf: DEMOCRATIZATION OF #ARTIFICIA...  \n",
       "1129  RT @bigdataconf: DEMOCRATIZATION OF #ARTIFICIA...  \n",
       "1137  Extending Human Lifespans: Using Artificial In...  \n",
       "1203  Using #AI to Find Bias in AI.\\nby @CadeMetz @n...  \n",
       "1227  Does Your Project Need Artificial Intelligence...  \n",
       "1257  RT @Paula_Piccard: How Artificial Intelligence...  \n",
       "1292  The Psychological And Cultural Impact Of #Arti...  \n",
       "1294  RT @IainLJBrown: Artificial intelligence makes...  \n",
       "1306  RT @IainLJBrown: Artificial intelligence makes...  \n",
       "1321  RT @IainLJBrown: Artificial intelligence makes...  \n",
       "1322  RT @Paula_Piccard: How Artificial Intelligence...  \n",
       "1341  RT @IainLJBrown: Artificial intelligence makes...  \n",
       "1397  Pentagon eyes artificial intelligence (AI) ena...  \n",
       "1434  RT @IainLJBrown: Artificial intelligence could...  \n",
       "1455  RT @WajdiAlkayal: Ai Vs Ml – What’s The Differ...  \n",
       "1486  RT @d4hio: RT @Terralogic_: Four Predictions F...  \n",
       "1487  RT @d4hio: RT @Terralogic_: Four Predictions F...  \n",
       "1489  RT @d4hio: RT @Terralogic_: Four Predictions F...  \n",
       "1524  RT @Paula_Piccard: What Are The Three Domains ...  \n",
       "1578  RT @gp_pulipaka: Best AI (Artificial Intellige...  \n",
       "1590  RT @odsc: Think, fight, feel: how video game a...  \n",
       "1602  RT @TACHOUHONER: Language as a key to artifici...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tweet_hashtag(\"DataScience\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>AuthorLocation</th>\n",
       "      <th>CreatedAt</th>\n",
       "      <th>RetweetCount</th>\n",
       "      <th>TweetLanguage</th>\n",
       "      <th>TweetText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>1415745098394996736</td>\n",
       "      <td></td>\n",
       "      <td>2021-07-15T18:48:29Z</td>\n",
       "      <td>170</td>\n",
       "      <td>en</td>\n",
       "      <td>RT @DeepLearn007: Amazing #AI Translates Menta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>1415926488801718272</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>2021-07-16T06:49:16Z</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>Why Global #ArtificialIntelligence \\n\\nis the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>1416485301925539840</td>\n",
       "      <td>Irvine, CA</td>\n",
       "      <td>2021-07-17T19:49:47Z</td>\n",
       "      <td>1</td>\n",
       "      <td>en</td>\n",
       "      <td>RT @SpirosMargaris: Researchers at @facebookai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>1416757077003931648</td>\n",
       "      <td>Austin, TX</td>\n",
       "      <td>2021-07-18T13:49:43Z</td>\n",
       "      <td>2</td>\n",
       "      <td>en</td>\n",
       "      <td>RT @SpirosMargaris: What are the Implications ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>1416757074030174208</td>\n",
       "      <td></td>\n",
       "      <td>2021-07-18T13:49:43Z</td>\n",
       "      <td>2</td>\n",
       "      <td>en</td>\n",
       "      <td>RT @SpirosMargaris: What are the Implications ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>1416787435535618048</td>\n",
       "      <td>U.K.</td>\n",
       "      <td>2021-07-18T15:50:21Z</td>\n",
       "      <td>12</td>\n",
       "      <td>en</td>\n",
       "      <td>RT @SpirosMargaris: What are the Implications ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>1417074345927745536</td>\n",
       "      <td>All Over the World</td>\n",
       "      <td>2021-07-19T10:50:26Z</td>\n",
       "      <td>4</td>\n",
       "      <td>en</td>\n",
       "      <td>RT @SpirosMargaris: Artificial Intelligence st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>943</th>\n",
       "      <td>1418614895818403840</td>\n",
       "      <td>Dallas, TX</td>\n",
       "      <td>2021-07-23T16:52:02Z</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>As the presence of #AI and #automation increas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1133</th>\n",
       "      <td>1419279456724791296</td>\n",
       "      <td>Northeast USA</td>\n",
       "      <td>2021-07-25T12:52:46Z</td>\n",
       "      <td>6</td>\n",
       "      <td>en</td>\n",
       "      <td>RT @SpirosMargaris: Good read\\n\\n#ArtificialIn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1135</th>\n",
       "      <td>1419294395287982080</td>\n",
       "      <td>Frankfurt on the Main, Germany</td>\n",
       "      <td>2021-07-25T13:52:07Z</td>\n",
       "      <td>25</td>\n",
       "      <td>en</td>\n",
       "      <td>RT @SpirosMargaris: What is #AI? \\n\\nEverythin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1204</th>\n",
       "      <td>1419566385806512128</td>\n",
       "      <td>Melbourne, Victoria, Australia</td>\n",
       "      <td>2021-07-26T07:52:55Z</td>\n",
       "      <td>193</td>\n",
       "      <td>en</td>\n",
       "      <td>RT @DeepLearn007: My Article: The Next Generat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1231</th>\n",
       "      <td>1419672038353084416</td>\n",
       "      <td>Lagos, Nigeria</td>\n",
       "      <td>2021-07-26T14:52:44Z</td>\n",
       "      <td>7</td>\n",
       "      <td>en</td>\n",
       "      <td>RT @SpirosMargaris: Does Your #Project \\n\\nNee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1418</th>\n",
       "      <td>1420472527848103936</td>\n",
       "      <td>Malta</td>\n",
       "      <td>2021-07-28T19:53:36Z</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>Artificial Intelligence Arrives at the Edge\\n\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1426</th>\n",
       "      <td>1420487640101523456</td>\n",
       "      <td></td>\n",
       "      <td>2021-07-28T20:53:39Z</td>\n",
       "      <td>0</td>\n",
       "      <td>fr</td>\n",
       "      <td>Can Artificial Intelligence be dangerous?\\n27 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1546</th>\n",
       "      <td>1420880149386612736</td>\n",
       "      <td>England, United Kingdom</td>\n",
       "      <td>2021-07-29T22:53:20Z</td>\n",
       "      <td>1</td>\n",
       "      <td>en</td>\n",
       "      <td>RT @richardkimphd: #ArtificialIntelligence in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1678</th>\n",
       "      <td>1421333233141231616</td>\n",
       "      <td>Kyiv, Ukraine</td>\n",
       "      <td>2021-07-31T04:53:44Z</td>\n",
       "      <td>4</td>\n",
       "      <td>en</td>\n",
       "      <td>RT @SpirosMargaris: Good read\\n\\nWhy #Artifici...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id                  AuthorLocation  \\\n",
       "142   1415745098394996736                                   \n",
       "200   1415926488801718272                           Kenya   \n",
       "367   1416485301925539840                      Irvine, CA   \n",
       "448   1416757077003931648                      Austin, TX   \n",
       "449   1416757074030174208                                   \n",
       "457   1416787435535618048                            U.K.   \n",
       "521   1417074345927745536              All Over the World   \n",
       "943   1418614895818403840                      Dallas, TX   \n",
       "1133  1419279456724791296                   Northeast USA   \n",
       "1135  1419294395287982080  Frankfurt on the Main, Germany   \n",
       "1204  1419566385806512128  Melbourne, Victoria, Australia   \n",
       "1231  1419672038353084416                  Lagos, Nigeria   \n",
       "1418  1420472527848103936                           Malta   \n",
       "1426  1420487640101523456                                   \n",
       "1546  1420880149386612736         England, United Kingdom   \n",
       "1678  1421333233141231616                   Kyiv, Ukraine   \n",
       "\n",
       "                 CreatedAt  RetweetCount TweetLanguage  \\\n",
       "142   2021-07-15T18:48:29Z           170            en   \n",
       "200   2021-07-16T06:49:16Z             0            en   \n",
       "367   2021-07-17T19:49:47Z             1            en   \n",
       "448   2021-07-18T13:49:43Z             2            en   \n",
       "449   2021-07-18T13:49:43Z             2            en   \n",
       "457   2021-07-18T15:50:21Z            12            en   \n",
       "521   2021-07-19T10:50:26Z             4            en   \n",
       "943   2021-07-23T16:52:02Z             0            en   \n",
       "1133  2021-07-25T12:52:46Z             6            en   \n",
       "1135  2021-07-25T13:52:07Z            25            en   \n",
       "1204  2021-07-26T07:52:55Z           193            en   \n",
       "1231  2021-07-26T14:52:44Z             7            en   \n",
       "1418  2021-07-28T19:53:36Z             0            en   \n",
       "1426  2021-07-28T20:53:39Z             0            fr   \n",
       "1546  2021-07-29T22:53:20Z             1            en   \n",
       "1678  2021-07-31T04:53:44Z             4            en   \n",
       "\n",
       "                                              TweetText  \n",
       "142   RT @DeepLearn007: Amazing #AI Translates Menta...  \n",
       "200   Why Global #ArtificialIntelligence \\n\\nis the ...  \n",
       "367   RT @SpirosMargaris: Researchers at @facebookai...  \n",
       "448   RT @SpirosMargaris: What are the Implications ...  \n",
       "449   RT @SpirosMargaris: What are the Implications ...  \n",
       "457   RT @SpirosMargaris: What are the Implications ...  \n",
       "521   RT @SpirosMargaris: Artificial Intelligence st...  \n",
       "943   As the presence of #AI and #automation increas...  \n",
       "1133  RT @SpirosMargaris: Good read\\n\\n#ArtificialIn...  \n",
       "1135  RT @SpirosMargaris: What is #AI? \\n\\nEverythin...  \n",
       "1204  RT @DeepLearn007: My Article: The Next Generat...  \n",
       "1231  RT @SpirosMargaris: Does Your #Project \\n\\nNee...  \n",
       "1418  Artificial Intelligence Arrives at the Edge\\n\\...  \n",
       "1426  Can Artificial Intelligence be dangerous?\\n27 ...  \n",
       "1546  RT @richardkimphd: #ArtificialIntelligence in ...  \n",
       "1678  RT @SpirosMargaris: Good read\\n\\nWhy #Artifici...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tweet_mention(\"SpirosMargaris\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_hashtag()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_specified_hashtag(\"FEATURED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_mentionned(1415291886860967936)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tweet_hashtag(\"machine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets[829].get_mention()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Je m'appelle Ahmad, j'ai 19 et j'étudie l'informatique à l'Université de Versaille Saint-Quention en Yvelines \""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_cleaning(\"Je m'appelle Ahmad, j'ai 19 et j'étudie l'informatique à l'Université de Versaille Saint-Quention en Yvelines 🎓\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
