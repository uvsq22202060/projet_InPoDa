{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json                         # module pour load le file\n",
    "import re                           # module pour retourner les hasthtags\n",
    "from textblob import TextBlob       # module pour analyser le sentiment du tweet\n",
    "import pandas as pd                 # module pour visualiser et comparer les tweets\n",
    "import matplotlib.pyplot as plt     \n",
    "from datetime import datetime\n",
    "import random as rd             \n",
    "import langid\n",
    "\n",
    "# Data utilis√© pour la cr√©ation des dictionnaires pour faciliter l'analyse de diagramme,...\n",
    "file = open(\"tweets.json\",\"r\")\n",
    "data =json.load(file)\n",
    "file.close()\n",
    "\n",
    "# Data utilis√© pour analyser visuellement les diff√©rentes caract√©ristiques d'un tweet\n",
    "data2 = pd.read_json(\"tweets.json\")\n",
    "df_data = pd.DataFrame(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tweet :\n",
    "    def __init__(self,id_tweet,location_tweet,creation_tweet,retweet_count,tweet_language,tweet_text) :\n",
    "        self.id = id_tweet\n",
    "        self.location = location_tweet\n",
    "        self.created = creation_tweet\n",
    "        self.retweet = retweet_count\n",
    "        self.language = tweet_language\n",
    "        self.text = tweet_text\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"Tweet id : {self.id}\\nAuthor Location : {self.location} \\nTweet Creation : {self.created} \\nNumber of Retweets : {self.retweet} \\nTweet Language : {self.language} \\nTweet Text : {self.text}\"\n",
    "    \n",
    "    def get_author(self):\n",
    "        id_tweet = self.id\n",
    "        return id_tweet\n",
    "    \n",
    "    def get_text(self):\n",
    "        return self.text\n",
    "    \n",
    "    def get_hashtags(self):\n",
    "        return re.findall(r\"#(\\w+)\", self.text)\n",
    "\n",
    "    def get_mention(self):\n",
    "        return re.findall(r\"@(\\w+)\", self.text)\n",
    "    \n",
    "    def get_sentiment(self):\n",
    "        text = TextBlob(self.text)\n",
    "        text_polarity = text.sentiment.polarity\n",
    "        if text_polarity > 0 :\n",
    "            return \"Positive\"\n",
    "        elif text_polarity < 0 :\n",
    "            return \"Negative\"\n",
    "        else :\n",
    "            return \"Neutral\" \n",
    "\n",
    "\n",
    "#instance/ objets de la class\n",
    "tweets = [Tweet(tweet[\"id\"],tweet[\"AuthorLocation\"],tweet[\"CreatedAt\"],tweet[\"RetweetCount\"],tweet[\"TweetLanguage\"],tweet[\"TweetText\"]) for tweet in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################################################################\n",
    "##########################################  AVEC LES DICTIONNAIRES   ####################################################\n",
    "#########################################################################################################################\n",
    "\n",
    "# Pour Top K Hashtags -> 2 fonctions\n",
    "\n",
    "# La premi√®re :\n",
    "def all_hashtag():\n",
    "    '''retourne tout les hashtags du fichier json dans une liste'''\n",
    "    l = []                                         # on intialise la liste qui va √™tre retourn√©e √† l'√©x√©cution de la fonction\n",
    "    for tweet in tweets:                           # on parcours tout les tweets (un par un)\n",
    "        if tweet.get_hashtags()== [] :             # on v√©rifie avec l'atribut de l'instance si la valeur retourner est  \"[]\" <- pas de valeur ; dans ce cas l√† on passe au tweet suivant\n",
    "            continue\n",
    "        else :\n",
    "            temp = tweet.get_hashtags()            # on affecte a temp (variable temporaire) la liste des hashtags de chaque tweet\n",
    "            for hashtag in temp :                  # on acc√®de √† chaque hashtag pr√©sent dans temp\n",
    "                l.append(hashtag)                  # on l'affecte √† la liste finale qu'on va retourner\n",
    "                \n",
    "    return l\n",
    "    \n",
    "   \n",
    "# La deuxi√®me :\n",
    "def top_hashtag(k):\n",
    "    '''retourne le top k (index) hashtag utilis√© dans la database'''\n",
    "    hashtags = all_hashtag()                       # utilisation de la fonction all_hashtag() pour r√©cup√©rer la liste compl√®te des hashtag\n",
    "    hashtag_count = {}                             # on initialise un dictionnaire vide pour compter chaque occurence de chaque hashtag\n",
    "    for hashtag in hashtags :                      # ici on prend chaque hashtag un par un, ici nomm√© \"e\" (pour √©l√©ment)\n",
    "        if hashtag in hashtag_count :              # on v√©rifie si \"hashtag\" est dans le dictionnaire qui compte les occurences\n",
    "            hashtag_count[hashtag] += 1            # dans ce cas l√† on incr√©mente sa valeur de 1\n",
    "        else :\n",
    "            hashtag_count[hashtag] = 1             # dans le cas contraire, on initialise la cl√© \"hashtag\" √† une valeur initiale de 1 \n",
    "\n",
    "    hashtag_count = dict(sorted(hashtag_count.items(),key = lambda x : x[1], reverse=True)) # on tri le dictionnaire en fonction des valeurs avec le lambda x[1] et reverse = True (de mani√®re croissante)\n",
    "    temp = list(hashtag_count.items())[:k]        # on converti le dictionnaire en une liste pour pouvoir effectu√© un slicing (afin d'obtenir les top k √©l√©ments) \n",
    "    top_k_hashtag = dict(temp)                    # on reconverti en dictionnaire afin de pouvoir manipuler les cl√©s et valeurs facilement et dans un odre pr√©cis\n",
    "    \n",
    "    # Diagramme avec plt\n",
    "    x_hashtag = list(top_k_hashtag.keys())        # on affecte √† la variable x_hashtag les cl√©s du dictionnaire (les hashtags (str))\n",
    "    y_occurence = list(top_k_hashtag.values())    # on affecte √† la variable y_occurence les valeurs des cl√©s du dictionnaire (les occurences)\n",
    "\n",
    "    plt.bar(x_hashtag,y_occurence)                # on cr√©er le diagramme en bar avec en x -> x_hashtag et en y -> y_occurence\n",
    "    plt.xlabel(\"Hashtag\")                         # \"Hashtag\" comme titre de l'axe des x\n",
    "    plt.ylabel(\"Occurence\")                       # \"Occurence\" comme titre de l'axe des y\n",
    "\n",
    "    plt.xticks(fontsize=6)                        # on pr√©cise la taille du texte pour les valeurs en x (les hashtags)\n",
    "    plt.show()                                    # affichage du diagramme\n",
    "\n",
    "    return top_k_hashtag                          # on retourne en m√™me temps le dictionnaire tri√© en ordre croissant des top k hashtags\n",
    "\n",
    "#########################################################################################################################\n",
    "\n",
    "# Pour Top K Users -> 2 fonctions \n",
    "\n",
    "# La premi√®re : \n",
    "def all_users():\n",
    "    '''retourne tout les utilisateurs pr√©sent dans le fichier json dans une liste'''\n",
    "    l = []                                       # on intialise la liste qui va √™tre retourn√©e √† l'√©x√©cution de la fonction\n",
    "    for tweet in tweets:                         # on parcours tout les tweets (un par un)\n",
    "        user = tweet.get_author()                # on extrait l'auteur gr√¢ce √† la m√©thode .get_author() qu'on place dans la variable user\n",
    "        l.append(user)                           # on ajoute √† la liste l'utilisateur/id du tweet\n",
    "                \n",
    "    return l\n",
    "\n",
    "# La deuxi√®me : \n",
    "def top_users(k):\n",
    "    '''retourne le top k (index) d'utilisateurs/id pr√©sent dans la database'''\n",
    "    users = all_users()                          # utilisation de la fonction all_users() pour r√©cup√©rer la liste compl√®te des utilisateurs\n",
    "    user_ntweet = {}                             # on initialise un dictionnaire vide pour compter chaque occurence de chaque id\n",
    "    for user in users :                          # ici on prend chaque id un par un, ici nomm√© \"user\"\n",
    "        if user in user_ntweet :                 # on v√©rifie si l'id est d√©j√† dans le dictionnaire\n",
    "            user_ntweet[user] += 1               # si c'est le ce cas, on incr√©mente sa valeur de 1 \n",
    "        else :\n",
    "            user_ntweet[user] = 1                # sinon on cr√©e une cl√© pour l'id correspondant et on initie sa valeur √† 1 \n",
    "\n",
    "    user_ntweet = dict(sorted(user_ntweet.items(), key = lambda x : x[1], reverse=True)) # on tri le dictionnaire en fonction des valeurs avec le lambda x[1] et reverse = True (de mani√®re croissante)\n",
    "    temp = list(user_ntweet.items())[:k]         # on converti le dictionnaire en une liste pour pouvoir effectu√© un slicing (afin d'obtenir les top k √©l√©ments)\n",
    "    top_k_users = dict(temp)                     # on reconverti en dictionnaire afin de pouvoir manipuler les cl√©s et valeurs facilement et dans un odre pr√©cis\n",
    "\n",
    "    x_user = list(top_k_users.keys())            # on affecte √† la variable x_user les cl√©s du dictionnaire (les id (str))\n",
    "    y_occurence = list(top_k_users.values())     # on affecte √† la variable y_occurence les valeurs du dictionnaire (les occurences)\n",
    "\n",
    "    plt.bar(x_user,y_occurence)                  # on cr√©er le diagramme en bar avec en x -> x_hashtag et en y -> y_occurence\n",
    "    plt.xlabel(\"User\")                           # \"User\" comme titre de l'axe des x\n",
    "    plt.ylabel(\"Occurence\")                      # \"Occurence\" comme titre de l'axe des y\n",
    "\n",
    "    plt.xticks(fontsize=5)                       # on pr√©cise la taille du texte pour les valeurs en x (les id)\n",
    "    plt.show()                                   # affichage du diagramme\n",
    "\n",
    "    return top_k_users                           # on retourne en m√™me temps le dictionnaire tri√© en ordre croissant des top k users\n",
    "\n",
    "#########################################################################################################################\n",
    "\n",
    "# Pour the top K mentions -> 2 fonctions \n",
    "\n",
    "# La premi√®re : \n",
    "def all_mentions():\n",
    "    '''retourne toutes les mentions de la database'''\n",
    "    l = []                                        # on initialise la liste qui va √™tre utilis√©e pour retourner les mentions √† l'√©x√©cution de la fonction\n",
    "    for tweet in tweets:\n",
    "        if tweet.get_mention()== [] :             # on v√©rifie avec l'atribut de l'instance si la valeur retourner est  \"[]\" <- pas de valeur ; dans ce cas l√† on passe au tweet suivant\n",
    "            continue\n",
    "        else :\n",
    "            mentions = tweet.get_mention()        # on place les mentions obtenues du tweet dans la variable temporaire mentions (qui va correspondre √† une liste) \n",
    "            for mention in mentions :             # on parcours chaque √©l√©ment de la liste (ils peuvent √™tre dans une liste de liste par exemple :[[mention],mention2,...])\n",
    "                l.append(mention)                 # et on l'ajoute √† notre liste finale\n",
    "                \n",
    "    return l\n",
    "\n",
    "def top_mention(k):\n",
    "    '''retourne le top k (index) d'utilisateurs/id pr√©sent dans la database'''\n",
    "    mentions = all_mentions()                       # utilisation de la fonction all_mentions() pour r√©cup√©rer la liste compl√®te des mentions\n",
    "    mention_ntweet = {}                             # on initialise un dictionnaire vide pour compter chaque occurence de chaque mention\n",
    "    for mention in mentions :                       # ici on prend chaque mention, une par une\n",
    "        if mention in mention_ntweet :              # on v√©rifie si la mention est pr√©sente dans le dictionnaire\n",
    "            mention_ntweet[mention] += 1            # dans ce cas l√† on incr√©mente la valeur corresponde √† la mention (la cl√©)\n",
    "        else :\n",
    "            mention_ntweet[mention] = 1             # dans le cas contraire on initie la cl√© correspondante √† la mention √† 1\n",
    "\n",
    "    mention_ntweet = dict(sorted(mention_ntweet.items(),key = lambda x : x[1], reverse=True)) # on tri le dictionnaire en fonction des valeurs avec le lambda x[1] et reverse = True (de mani√®re croissante)\n",
    "    temp = list(mention_ntweet.items())[:k]         # on converti le dictionnaire en une liste pour pouvoir effectu√© un slicing (afin d'obtenir les top k √©l√©ments)\n",
    "    top_k_mentions = dict(temp)                     # on reconverti la liste en dictionnaire tri√© en ordre croissant des top k mentions\n",
    "\n",
    "    x_mention = list(top_k_mentions.keys())         # on affecte √† la variable x_mention les cl√©s du dictionnaire (les mentions (str))\n",
    "    y_occurence = list(top_k_mentions.values())     # on affecte √† la variable y_occurence les valeurs du dictionnaire (les occurences)\n",
    "\n",
    "    plt.bar(x_mention,y_occurence)                  # on cr√©er le diagramme en bar avec en x -> x_mention et en y -> y_occurence\n",
    "    plt.xlabel(\"Mention\",)                          # on cr√©er le diagramme en bar avec en x -> x_mention\n",
    "    plt.ylabel(\"Occurence\")                         # on cr√©er le diagramme en bar avec en y -> y_occurence\n",
    "\n",
    "    plt.xticks(fontsize=7)                          # on pr√©cise la taille du texte pour les valeurs en x (les mentions)\n",
    "    plt.show()                                      # affichage du diagramme\n",
    "\n",
    "    return top_k_mentions                           # on retourne en m√™me temps le dictionnaire tri√© en ordre croissant des top k mentions\n",
    "\n",
    "#########################################################################################################################\n",
    "\n",
    "def top_topics():\n",
    "    pass\n",
    "\n",
    "\n",
    "###########################################################################################################################\n",
    "################################################## AVEC LES DATAFRAMES   ##################################################\n",
    "###########################################################################################################################\n",
    "\n",
    "\n",
    "def all_tweet_mention(mention):\n",
    "    '''retourne l'ensemble des tweets mentionnant un utilisateur sp√©cifique dans un dataframe'''                                                               \n",
    "    return df_data[df_data[\"TweetText\"].str.contains(f\"@{mention}\",regex=False)]              # on tri les lignes de la database pour extraire seulement celle qui contiennent @mention dans la colonne \n",
    "\n",
    "def all_tweet_hashtag(hashtag):\n",
    "    '''retourne l'ensemble des tweets faisant r√©f√©rence √† un hashtag sp√©cifique'''                                                               \n",
    "    return df_data[df_data[\"TweetText\"].str.contains(f\"#{hashtag}\",regex=False)]              # on tri les lignes de la database pour extraire seulement celle qui contiennent #hashtag dans la colonne de TweetText\n",
    "\n",
    "def user_specified_hashtag(hashtag):\n",
    "    '''retourne les id de chaque utilisateur mentionnant un hashtag sp√©cifique'''                                                         \n",
    "    return df_data[df_data[\"TweetText\"].str.contains(f\"#{hashtag}\",regex=True)].get(\"id\")     # on tri les lignes de la database pour extraire  les #hashtag pr√©sent dans la colonne TweetText et on extrait seulement les id\n",
    "\n",
    "def user_mentionned(user):\n",
    "    '''retourne les utilisateurs mentionn√©s par un utilisateur sp√©cifique'''                                                                \n",
    "    text = str(df_data[df_data[\"id\"]==user].get(\"TweetText\"))                                 # on attribue √† la variable text le texte du tweet qui correspond √† l'utilisiateur sp√©cifique\n",
    "    return re.findall(r\"@(\\w+)\", text)                                                        # on nettoie le text en extrayant les mentions avec le r\"@(\\w+)\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################# PARTIE SUR LA GESTION DES TWEETS #############################################################\n",
    "\n",
    "\n",
    "def text_cleaning(text):\n",
    "  '''retourne le texte entr√©e, nettoyer de tout symboles/emojis'''\n",
    "  # Pattern trouv√© sur le lien suivant : https://gist.github.com/Alex-Just/e86110836f3f93fe7932290526529cd1#gistcomment-3208085\n",
    "  \n",
    "  pattern = re.compile(\n",
    "    \"([\"\n",
    "    \"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "    \"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "    \"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "    \"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "    \"\\U0001F700-\\U0001F77F\"  # alchemical symbols\n",
    "    \"\\U0001F780-\\U0001F7FF\"  # Geometric Shapes Extended\n",
    "    \"\\U0001F800-\\U0001F8FF\"  # Supplemental Arrows-C\n",
    "    \"\\U0001F900-\\U0001F9FF\"  # Supplemental Symbols and Pictographs\n",
    "    \"\\U0001FA00-\\U0001FA6F\"  # Chess Symbols\n",
    "    \"\\U0001FA70-\\U0001FAFF\"  # Symbols and Pictographs Extended-A\n",
    "    \"\\U00002702-\\U000027B0\"  # Dingbats\n",
    "    \"])\"\n",
    "                      )\n",
    "  \n",
    "  text = re.sub(pattern, r'', text)                  # ici l'expression reguli√®re va supprimer (sub en anglais) les √©mojis et caract√®res contenus dans le pattern\n",
    "  return text\n",
    "\n",
    "def transfer(source, destination):\n",
    "  '''retourne un \"fichier_atterissage.json\", une base de donn√©e nettoyer'''\n",
    "  with open(source,\"r\") as source_file, open(destination,\"w\") as destination_file :       # on ouvre le fichier source (-> source_file) et fichier destination (-> destination_file)\n",
    "\n",
    "      content_source = source_file.read()                        # on extrait le contenu de notre fichier source que l'on attribue √† la variable content_source\n",
    "      content_source = text_cleaning(content_source)             # \n",
    "\n",
    "      destination_file.write(content_source)\n",
    "\n",
    "transfer(\"tweets.json\",\"fichier_atterrissage.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################# PARTIE SUR LA CREATION DE TWEET #############################################################\n",
    "\n",
    "def creation_time():\n",
    "    '''retourne la date,heure, ... actuelle dans le format utilis√© dans le base de donn√©e'''\n",
    "    actual_time = datetime.now()                                          # on attribue la date actuelle √† la variable actual_time \n",
    "    actual_time = actual_time.strftime(\"%Y-%m-%dT%H:%M:%SZ\")              # on reformatise la date avec le format correspondant au fichier json, https://docs.python.org/3/library/datetime.html#strftime-strptime-behavior\n",
    "    return actual_time\n",
    "\n",
    "def random_location():\n",
    "    '''retourner une ville al√©atoire pour simuler la localisation de l'auteur du tweet'''                                                    \n",
    "    locations =[                                                          # locations est une liste de Ville, Pays\n",
    "                \"Tokyo, Japan\", \n",
    "                \"New York City, United-States\",\n",
    "                \"London, England\",\n",
    "                \"Pekin, China\",\n",
    "                \"Paris, France\",\n",
    "                \"Montreal, Canada\",\n",
    "                \"Madrid, Spain\",\n",
    "                \"Los Angeles, United-States\",\n",
    "                \"Delhi, India\",\n",
    "                \"Beirut, Lebanon\",\n",
    "                \"Versailles, France\",\n",
    "                \"Amsterdam, Netherland\",\n",
    "                \"Shanghai, China\",\n",
    "                \"Moscou, Russia\",\n",
    "                \"S√£o Paulo, Brasil\"\n",
    "                ]\n",
    "    \n",
    "    return locations[rd.randint(0,len(locations)-1)]                     # on va retourner un ville al√©atoire avec l'utilsation du module random (pour l'index)\n",
    "\n",
    "def create_tweet():\n",
    "    '''Fonction qui va permettre d'√©crire un tweet et de l'int√©grer dans la base de donn√©e'''  \n",
    "\n",
    "    text_tweet = text_cleaning(input(\"Que voulez vous tweetez ?\"))       # le sujet de notre tweet est r√©cup√©rer dans la variable text_tweet\n",
    "    tweet_lang,_ = langid.classify(text_tweet)                           # la langue est extraite de la variable text_tweet grace au module langid\n",
    "    tweet = {                                                            # dictionnaire qui va contenir les informations sur le tweet\n",
    "        \"id\": rd.randint(1000000000000000000,2000000000000000000),       # on attribue un id al√©atoire dans un interval semblable √† celui de base\n",
    "        \"AuthorLocation\": random_location(),\n",
    "        \"CreatedAt\": creation_time() ,\n",
    "        \"RetweetCount\": rd.randint(1,10),\n",
    "        \"TweetLanguage\": tweet_lang,\n",
    "        \"TweetText\": text_tweet                                           # √† corriger pour les √© etc on obtient /u... https://stackoverflow.com/questions/40412714/using-json-dumps-with-ensure-ascii-true\n",
    "            }\n",
    "\n",
    "    try:\n",
    "        with open(\"filetest.json\", \"r\") as file:\n",
    "            database = json.load(file)\n",
    "    except FileNotFoundError:\n",
    "         \n",
    "         database = []\n",
    "\n",
    "    \n",
    "    database.append(tweet)\n",
    "\n",
    "    \n",
    "    with open(\"filetest.json\", \"w\") as file:\n",
    "        json.dump(database, file,indent=3,ensure_ascii=False)            # sans le ensure ascii = False on aurait des \\u... quand on mets des accents \n",
    "\n",
    "create_tweet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################## TESTS ########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_hashtag()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tweet_hashtag(\"ArtificialIntelligence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_mentionned(1418705513660010496)        # √† corriger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tweet_hashtag(\"MachineLearning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tweet_mention(\"nigewillson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_mentionned(1415291886860967936)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_hashtag(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test for Top k hashtags\n",
    "all_hashtag()\n",
    "top_hashtag(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test for Top k users\n",
    "all_users()\n",
    "top_users(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test for Top k mentions\n",
    "all_mentions()\n",
    "top_mention(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tweet_hashtag(\"DataScience\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tweet_mention(\"SpirosMargaris\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_hashtag()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_specified_hashtag(\"FEATURED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_mentionned(1415291886860967936)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tweet_hashtag(\"machine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets[829].get_mention()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_cleaning(\"Je m'appelle Ahmad, j'ai 19 et j'√©tudie l'informatique √† l'Universit√© de Versaille Saint-Quention en Yvelines üéì\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
