{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################# PARTIE SUR LES IMPORTS  #############################################################\n",
    "import json                         # module pour load le file\n",
    "import re                           # module pour retourner les hasthtags\n",
    "from textblob import TextBlob       # module pour analyser le sentiment du tweet\n",
    "import pandas as pd                 # module pour visualiser et comparer les tweets\n",
    "import matplotlib.pyplot as plt     # module pour la création de Diagramme\n",
    "from datetime import datetime       # module pour manipuler l'heure \n",
    "import random as rd                 # module pour générer des éléments aléatoires\n",
    "import langid                       # module pour reconnaitre la langue d'un tweet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################# PARTIE SUR LA GESTION DES TWEETS #############################################################\n",
    "\n",
    "def text_cleaning(text):\n",
    "  '''retourne le texte entrée, nettoyer de tout symboles/emojis'''\n",
    "  # Pattern trouvé sur le lien suivant : https://gist.github.com/Alex-Just/e86110836f3f93fe7932290526529cd1#gistcomment-3208085\n",
    "  \n",
    "  pattern = re.compile(\n",
    "    \"([\"\n",
    "    \"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "    \"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "    \"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "    \"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "    \"\\U0001F700-\\U0001F77F\"  # alchemical symbols\n",
    "    \"\\U0001F780-\\U0001F7FF\"  # Geometric Shapes Extended\n",
    "    \"\\U0001F800-\\U0001F8FF\"  # Supplemental Arrows-C\n",
    "    \"\\U0001F900-\\U0001F9FF\"  # Supplemental Symbols and Pictographs\n",
    "    \"\\U0001FA00-\\U0001FA6F\"  # Chess Symbols\n",
    "    \"\\U0001FA70-\\U0001FAFF\"  # Symbols and Pictographs Extended-A\n",
    "    \"\\U00002702-\\U000027B0\"  # Dingbats\n",
    "    \"])\"\n",
    "                      )\n",
    "  \n",
    "  text = re.sub(pattern, r'', text)                  # ici l'expression regulière va supprimer (sub en anglais) les émojis et caractères contenus dans le pattern\n",
    "  return text\n",
    "\n",
    "def transfer(source, destination):\n",
    "  '''retourne un \"fichier_atterissage.json\", une base de donnée nettoyer'''\n",
    "  with open(source,\"r\") as source_file, open(destination,\"w\") as destination_file :       # on ouvre le fichier source (-> source_file) et fichier destination (-> destination_file)\n",
    "\n",
    "      content_source = source_file.read()                        # on extrait le contenu de notre fichier source que l'on attribue à la variable content_source\n",
    "      content_source = text_cleaning(content_source)             # on nettoie le contenu obtenu (pour supprimer les emojis...)\n",
    "\n",
    "      destination_file.write(content_source)                     # on écrit le contenu dans le fichier de destination\n",
    "\n",
    "transfer(\"tweets.json\",\"fichier_atterrissage.json\")\n",
    "\n",
    "# Data utilisé pour la création des dictionnaires pour faciliter l'analyse de diagramme,...\n",
    "file = open(\"fichier_atterrissage.json\",\"r\")\n",
    "data =json.load(file)\n",
    "file.close()\n",
    "\n",
    "# Data utilisé pour analyser visuellement les différentes caractéristiques d'un tweet\n",
    "data2 = pd.read_json(\"fichier_atterrissage.json\")\n",
    "df_data = pd.DataFrame(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################# PARTIE SUR LA CLASS \"Tweet\" #############################################################\n",
    "class Tweet :\n",
    "    def __init__(self,id_tweet,location_tweet,creation_tweet,retweet_count,tweet_language,tweet_text) :\n",
    "        self.id = id_tweet\n",
    "        self.location = location_tweet\n",
    "        self.created = creation_tweet\n",
    "        self.retweet = retweet_count\n",
    "        self.language = tweet_language\n",
    "        self.text = tweet_text\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"Tweet id : {self.id}\\nAuthor Location : {self.location} \\nTweet Creation : {self.created} \\nNumber of Retweets : {self.retweet} \\nTweet Language : {self.language} \\nTweet Text : {self.text}\"\n",
    "    \n",
    "    def get_author(self):\n",
    "        id_tweet = self.id\n",
    "        return id_tweet\n",
    "    \n",
    "    def get_text(self):\n",
    "        return self.text\n",
    "    \n",
    "    def get_hashtags(self):\n",
    "        return re.findall(r\"#(\\w+)\", self.text)\n",
    "\n",
    "    def get_mention(self):\n",
    "        return re.findall(r\"@(\\w+)\", self.text)\n",
    "    \n",
    "    def get_sentiment(self):\n",
    "        text = TextBlob(self.text)\n",
    "        text_polarity = text.sentiment.polarity\n",
    "        if text_polarity > 0 :\n",
    "            return \"Positive\"\n",
    "        elif text_polarity < 0 :\n",
    "            return \"Negative\"\n",
    "        else :\n",
    "            return \"Neutral\" \n",
    "\n",
    "\n",
    "#instance/ objets de la class\n",
    "tweets = [Tweet(tweet[\"id\"],tweet[\"AuthorLocation\"],tweet[\"CreatedAt\"],tweet[\"RetweetCount\"],tweet[\"TweetLanguage\"],tweet[\"TweetText\"]) for tweet in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################################################################\n",
    "##########################################  AVEC LES DICTIONNAIRES   ####################################################\n",
    "#########################################################################################################################\n",
    "\n",
    "# Pour Top K Hashtags -> 2 fonctions\n",
    "\n",
    "# La première :\n",
    "def all_hashtag():\n",
    "    '''retourne tout les hashtags du fichier json dans une liste'''\n",
    "    l = []                                         # on intialise la liste qui va être retournée à l'éxécution de la fonction\n",
    "    for tweet in tweets:                           # on parcours tout les tweets (un par un)\n",
    "        if tweet.get_hashtags()== [] :             # on vérifie avec l'atribut de l'instance si la valeur retourner est  \"[]\" <- pas de valeur ; dans ce cas là on passe au tweet suivant\n",
    "            continue\n",
    "        else :\n",
    "            temp = tweet.get_hashtags()            # on affecte a temp (variable temporaire) la liste des hashtags de chaque tweet\n",
    "            for hashtag in temp :                  # on accède à chaque hashtag présent dans temp\n",
    "                l.append(hashtag)                  # on l'affecte à la liste finale qu'on va retourner\n",
    "                \n",
    "    return l\n",
    "    \n",
    "   \n",
    "# La deuxième :\n",
    "def top_hashtag(k):\n",
    "    '''retourne le top k hashtag utilisé dans la database'''\n",
    "    hashtags = all_hashtag()                       # utilisation de la fonction all_hashtag() pour récupérer la liste complète des hashtag\n",
    "    hashtag_count = {}                             # on initialise un dictionnaire vide pour compter chaque occurence de chaque hashtag\n",
    "    for hashtag in hashtags :                      # ici on prend chaque hashtag un par un, ici nommé \"e\" (pour élément)\n",
    "        if hashtag in hashtag_count :              # on vérifie si \"hashtag\" est dans le dictionnaire qui compte les occurences\n",
    "            hashtag_count[hashtag] += 1            # dans ce cas là on incrémente sa valeur de 1\n",
    "        else :\n",
    "            hashtag_count[hashtag] = 1             # dans le cas contraire, on initialise la clé \"hashtag\" à une valeur initiale de 1 \n",
    "\n",
    "    hashtag_count = dict(sorted(hashtag_count.items(),key = lambda x : x[1], reverse=True)) # on tri le dictionnaire en fonction des valeurs avec le lambda x[1] et reverse = True (de manière croissante)\n",
    "    temp = list(hashtag_count.items())[:k]        # on converti le dictionnaire en une liste pour pouvoir effectué un slicing (afin d'obtenir les top k éléments) \n",
    "    top_k_hashtag = dict(temp)                    # on reconverti en dictionnaire afin de pouvoir manipuler les clés et valeurs facilement et dans un odre précis\n",
    "    \n",
    "    # Diagramme avec plt\n",
    "    x_hashtag = list(top_k_hashtag.keys())        # on affecte à la variable x_hashtag les clés du dictionnaire (les hashtags (str))\n",
    "    y_occurence = list(top_k_hashtag.values())    # on affecte à la variable y_occurence les valeurs des clés du dictionnaire (les occurences)\n",
    "\n",
    "    plt.bar(x_hashtag,y_occurence)                # on créer le diagramme en bar avec en x -> x_hashtag et en y -> y_occurence\n",
    "    plt.xlabel(\"Hashtag\")                         # \"Hashtag\" comme titre de l'axe des x\n",
    "    plt.ylabel(\"Occurence\")                       # \"Occurence\" comme titre de l'axe des y\n",
    "\n",
    "    plt.xticks(fontsize=6)                        # on précise la taille du texte pour les valeurs en x (les hashtags)\n",
    "    plt.show()                                    # affichage du diagramme\n",
    "\n",
    "    return top_k_hashtag                          # on retourne en même temps le dictionnaire trié en ordre croissant des top k hashtags\n",
    "\n",
    "#########################################################################################################################\n",
    "\n",
    "# Pour Top K Users -> 2 fonctions \n",
    "\n",
    "# La première : \n",
    "def all_users():\n",
    "    '''retourne tout les utilisateurs présent dans le fichier json dans une liste'''\n",
    "    l = []                                       # on intialise la liste qui va être retournée à l'éxécution de la fonction\n",
    "    for tweet in tweets:                         # on parcours tout les tweets (un par un)\n",
    "        user = tweet.get_author()                # on extrait l'auteur grâce à la méthode .get_author() qu'on place dans la variable user\n",
    "        l.append(user)                           # on ajoute à la liste l'utilisateur/id du tweet\n",
    "                \n",
    "    return l\n",
    "\n",
    "# La deuxième : \n",
    "def top_users(k):\n",
    "    '''retourne le top k d'utilisateurs/id présent dans la database'''\n",
    "    users = all_users()                          # utilisation de la fonction all_users() pour récupérer la liste complète des utilisateurs\n",
    "    user_ntweet = {}                             # on initialise un dictionnaire vide pour compter chaque occurence de chaque id\n",
    "    for user in users :                          # ici on prend chaque id un par un, ici nommé \"user\"\n",
    "        if user in user_ntweet :                 # on vérifie si l'id est déjà dans le dictionnaire\n",
    "            user_ntweet[user] += 1               # si c'est le ce cas, on incrémente sa valeur de 1 \n",
    "        else :\n",
    "            user_ntweet[user] = 1                # sinon on crée une clé pour l'id correspondant et on initie sa valeur à 1 \n",
    "\n",
    "    user_ntweet = dict(sorted(user_ntweet.items(), key = lambda x : x[1], reverse=True)) # on tri le dictionnaire en fonction des valeurs avec le lambda x[1] et reverse = True (de manière croissante)\n",
    "    temp = list(user_ntweet.items())[:k]         # on converti le dictionnaire en une liste pour pouvoir effectué un slicing (afin d'obtenir les top k éléments)\n",
    "    top_k_users = dict(temp)                     # on reconverti en dictionnaire afin de pouvoir manipuler les clés et valeurs facilement et dans un odre précis\n",
    "\n",
    "    x_user = list(top_k_users.keys())            # on affecte à la variable x_user les clés du dictionnaire (les id (str))\n",
    "    y_occurence = list(top_k_users.values())     # on affecte à la variable y_occurence les valeurs du dictionnaire (les occurences)\n",
    "\n",
    "    plt.bar(x_user,y_occurence)                  # on créer le diagramme en bar avec en x -> x_hashtag et en y -> y_occurence\n",
    "    plt.xlabel(\"User\")                           # \"User\" comme titre de l'axe des x\n",
    "    plt.ylabel(\"Occurence\")                      # \"Occurence\" comme titre de l'axe des y\n",
    "\n",
    "    plt.xticks(fontsize=5)                       # on précise la taille du texte pour les valeurs en x (les id)\n",
    "    plt.show()                                   # affichage du diagramme\n",
    "\n",
    "    return top_k_users                           # on retourne en même temps le dictionnaire trié en ordre croissant des top k users\n",
    "\n",
    "#########################################################################################################################\n",
    "\n",
    "# Pour the top K mentions -> 2 fonctions \n",
    "\n",
    "# La première : \n",
    "def all_mentions():\n",
    "    '''retourne toutes les mentions de la database'''\n",
    "    l = []                                        # on initialise la liste qui va être utilisée pour retourner les mentions à l'éxécution de la fonction\n",
    "    for tweet in tweets:\n",
    "        if tweet.get_mention()== [] :             # on vérifie avec l'atribut de l'instance si la valeur retourner est  \"[]\" <- pas de valeur ; dans ce cas là on passe au tweet suivant\n",
    "            continue\n",
    "        else :\n",
    "            mentions = tweet.get_mention()        # on place les mentions obtenues du tweet dans la variable temporaire mentions (qui va correspondre à une liste) \n",
    "            for mention in mentions :             # on parcours chaque élément de la liste (ils peuvent être dans une liste de liste par exemple :[[mention],mention2,...])\n",
    "                l.append(mention)                 # et on l'ajoute à notre liste finale\n",
    "                \n",
    "    return l\n",
    "\n",
    "def top_mention(k):\n",
    "    '''retourne le top k d'utilisateurs/id présent dans la database'''\n",
    "    mentions = all_mentions()                       # utilisation de la fonction all_mentions() pour récupérer la liste complète des mentions\n",
    "    mention_ntweet = {}                             # on initialise un dictionnaire vide pour compter chaque occurence de chaque mention\n",
    "    for mention in mentions :                       # ici on prend chaque mention, une par une\n",
    "        if mention in mention_ntweet :              # on vérifie si la mention est présente dans le dictionnaire\n",
    "            mention_ntweet[mention] += 1            # dans ce cas là on incrémente la valeur corresponde à la mention (la clé)\n",
    "        else :\n",
    "            mention_ntweet[mention] = 1             # dans le cas contraire on initie la clé correspondante à la mention à 1\n",
    "\n",
    "    mention_ntweet = dict(sorted(mention_ntweet.items(),key = lambda x : x[1], reverse=True)) # on tri le dictionnaire en fonction des valeurs avec le lambda x[1] et reverse = True (de manière croissante)\n",
    "    temp = list(mention_ntweet.items())[:k]         # on converti le dictionnaire en une liste pour pouvoir effectué un slicing (afin d'obtenir les top k éléments)\n",
    "    top_k_mentions = dict(temp)                     # on reconverti la liste en dictionnaire trié en ordre croissant des top k mentions\n",
    "\n",
    "    x_mention = list(top_k_mentions.keys())         # on affecte à la variable x_mention les clés du dictionnaire (les mentions (str))\n",
    "    y_occurence = list(top_k_mentions.values())     # on affecte à la variable y_occurence les valeurs du dictionnaire (les occurences)\n",
    "\n",
    "    plt.bar(x_mention,y_occurence)                  # on créer le diagramme en bar avec en x -> x_mention et en y -> y_occurence\n",
    "    plt.xlabel(\"Mention\",)                          # on créer le diagramme en bar avec en x -> x_mention\n",
    "    plt.ylabel(\"Occurence\")                         # on créer le diagramme en bar avec en y -> y_occurence\n",
    "\n",
    "    plt.xticks(fontsize=7)                          # on précise la taille du texte pour les valeurs en x (les mentions)\n",
    "    plt.show()                                      # affichage du diagramme\n",
    "\n",
    "    return top_k_mentions                           # on retourne en même temps le dictionnaire trié en ordre croissant des top k mentions\n",
    "\n",
    "#########################################################################################################################\n",
    "\n",
    "def top_topics():\n",
    "    '''retourne le top k topics/sujets présent dans la database'''\n",
    "    pass\n",
    "\n",
    "\n",
    "###########################################################################################################################\n",
    "################################################## AVEC LES DATAFRAMES   ##################################################\n",
    "###########################################################################################################################\n",
    "\n",
    "\n",
    "def all_tweet_mention(mention):\n",
    "    '''retourne l'ensemble des tweets mentionnant un utilisateur spécifique dans un dataframe'''                                                               \n",
    "    return df_data[df_data[\"TweetText\"].str.contains(f\"@{mention}\",regex=False)]              # on tri les lignes de la database pour extraire seulement celle qui contiennent @mention dans la colonne \n",
    "\n",
    "def all_tweet_hashtag(hashtag):\n",
    "    '''retourne l'ensemble des tweets faisant référence à un hashtag spécifique'''                                                               \n",
    "    return df_data[df_data[\"TweetText\"].str.contains(f\"#{hashtag}\",regex=False)]              # on tri les lignes de la database pour extraire seulement celle qui contiennent #hashtag dans la colonne de TweetText\n",
    "\n",
    "def user_specified_hashtag(hashtag):\n",
    "    '''retourne les id de chaque utilisateur mentionnant un hashtag spécifique'''                                                         \n",
    "    return df_data[df_data[\"TweetText\"].str.contains(f\"#{hashtag}\",regex=True)].get(\"id\")     # on tri les lignes de la database pour extraire  les #hashtag présent dans la colonne TweetText et on extrait seulement les id\n",
    "\n",
    "def user_mentionned(user):\n",
    "    '''retourne les utilisateurs mentionnés par un utilisateur spécifique'''                                                                \n",
    "    text = str(df_data[df_data[\"id\"]==user].get(\"TweetText\"))                                 # on attribue à la variable text le texte du tweet qui correspond à l'utilisiateur spécifique\n",
    "    return re.findall(r\"@(\\w+)\", text)                                                        # on nettoie le text en extrayant les mentions avec le r\"@(\\w+)\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################# PARTIE SUR LA CREATION DE TWEET #############################################################\n",
    "\n",
    "def creation_time():\n",
    "    '''retourne la date,heure, ... actuelle dans le format utilisé dans le base de donnée'''\n",
    "    actual_time = datetime.now()                                          # on attribue la date actuelle à la variable actual_time \n",
    "    actual_time = actual_time.strftime(\"%Y-%m-%dT%H:%M:%SZ\")              # on reformatise la date avec le format correspondant au fichier json, https://docs.python.org/3/library/datetime.html#strftime-strptime-behavior\n",
    "    return actual_time\n",
    "\n",
    "def random_location():\n",
    "    '''retourner une ville aléatoire pour simuler la localisation de l'auteur du tweet'''                                                    \n",
    "    locations =[                                                          # locations est une liste de Ville, Pays\n",
    "                \"Tokyo, Japan\", \n",
    "                \"New York City, United-States\",\n",
    "                \"London, England\",\n",
    "                \"Pekin, China\",\n",
    "                \"Paris, France\",\n",
    "                \"Montreal, Canada\",\n",
    "                \"Madrid, Spain\",\n",
    "                \"Los Angeles, United-States\",\n",
    "                \"Delhi, India\",\n",
    "                \"Beirut, Lebanon\",\n",
    "                \"Versailles, France\",\n",
    "                \"Amsterdam, Netherland\",\n",
    "                \"Shanghai, China\",\n",
    "                \"Moscou, Russia\",\n",
    "                \"São Paulo, Brasil\"\n",
    "                ]\n",
    "    \n",
    "    return locations[rd.randint(0,len(locations)-1)]                     # on va retourner un ville aléatoire avec l'utilsation du module random (pour l'index)\n",
    "\n",
    "def create_tweet():\n",
    "    '''Fonction qui va permettre d'écrire un tweet et de l'intégrer dans la base de donnée'''  \n",
    "\n",
    "    text_tweet = text_cleaning(input(\"Que voulez vous tweetez ?\"))       # le contenu de notre tweet est récupérer dans la variable text_tweet après être nettoyé\n",
    "    tweet_lang,_ = langid.classify(text_tweet)                           # la langue est extraite de la variable text_tweet grace au module langid\n",
    "    tweet = {                                                            # dictionnaire qui va contenir les informations sur le tweet\n",
    "        \"id\": str(rd.randint(1000000000000000000,2000000000000000000)),  # on attribue un id aléatoire dans un interval semblable à celui de base\n",
    "        \"AuthorLocation\": random_location(),                             # on appelle la fonction random_location() pour générer un emplacement aléatoire pour le tweet\n",
    "        \"CreatedAt\": creation_time(),                                    # on extrait l'heure actuelle où est rédigé le tweet (tout en faisant attention à sa mise en forme, voir fonction)\n",
    "        \"RetweetCount\": rd.randint(1,10),                                # on génère un nombre de retweet\n",
    "        \"TweetLanguage\": tweet_lang,                                     # on extrait la langue du tweet avec le module langid\n",
    "        \"TweetText\": text_tweet                                          \n",
    "            }\n",
    "\n",
    "    try:                                                                 # permet de vérifier si le fichier est non vide\n",
    "        with open(\"fichier_atterrissage.json\", \"r\") as file:\n",
    "            database = json.load(file)                                   # si non vide alors on load/charge le contenu dans la variable database\n",
    "    except FileNotFoundError:                                            # sinon, on crée la base de donnée nous même\n",
    "         \n",
    "         database = []                                                   # création de la base de donnée (en liste pour pouvoir manipuler les tweets correctement)\n",
    "\n",
    "\n",
    "    database.append(tweet)                                               # on ajoute à la suite de la database notre tweet créer\n",
    "\n",
    "    \n",
    "    with open(\"fichier_atterrissage.json\", \"w\") as file:\n",
    "        json.dump(database, file,indent=3,ensure_ascii=False)            # sans le ensure ascii = False on aurait des \\u... quand on mets des accents https://stackoverflow.com/questions/40412714/using-json-dumps-with-ensure-ascii-true\n",
    "\n",
    "create_tweet()\n",
    "\n",
    "file = open(\"fichier_atterrissage.json\",\"r\")\n",
    "data =json.load(file)\n",
    "file.close()\n",
    "\n",
    "# Mise à jour de la database (avec le tweet créé ajouté)\n",
    "data2 = pd.read_json(\"fichier_atterrissage.json\")\n",
    "df_data = pd.DataFrame(data2)\n",
    "#instance/ objets de la class\n",
    "tweets = [Tweet(tweet[\"id\"],tweet[\"AuthorLocation\"],tweet[\"CreatedAt\"],tweet[\"RetweetCount\"],tweet[\"TweetLanguage\"],tweet[\"TweetText\"]) for tweet in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################## TESTS ########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm very happy, i finally fixed my issue with saving the incoming data @Ahmad  ! #code #debug #InPoDa #projet\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets[-1].get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Positive'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets[-1].get_sentiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hdatasystems',\n",
       " 'Artificia',\n",
       " 'MachineLearning',\n",
       " 'DataScience',\n",
       " 'Python',\n",
       " 'AI',\n",
       " '100DaysOfCode',\n",
       " 'DEVCommunity',\n",
       " 'IoT',\n",
       " 'flutte',\n",
       " 'artificialintelligence',\n",
       " 'AI',\n",
       " 'ArtificialIntelligence',\n",
       " 'DeepLearning',\n",
       " 'AI',\n",
       " 'ArtificialIntelligence',\n",
       " 'FEATURED',\n",
       " 'COURSES',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'FEATURED',\n",
       " 'COURSES',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'FEATURED',\n",
       " 'COURSES',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'data',\n",
       " 'science',\n",
       " 'Tensorflow',\n",
       " 'artificial',\n",
       " 'intelligence',\n",
       " 'python',\n",
       " '100daysofcode',\n",
       " 'coding',\n",
       " 'udemy',\n",
       " 'Artificial_Intelligence',\n",
       " 'ai',\n",
       " 'ml',\n",
       " 'dl',\n",
       " 'artificialintelligence',\n",
       " 'Intela',\n",
       " 'ArtificialIntelligence',\n",
       " 'Ar',\n",
       " 'ArtificialIntelligenc',\n",
       " 'GovCloudWorldNews',\n",
       " 'ArtificialIntelligence',\n",
       " 'Java',\n",
       " 'Bitcoin',\n",
       " 'SciketLearn',\n",
       " 'ComputerVision',\n",
       " 'DeepLearningFramework',\n",
       " 'AutonomousVehicles',\n",
       " 'NFT',\n",
       " 'ImageProcessing',\n",
       " 'React',\n",
       " 'LinearAlgebra',\n",
       " 'Bluetooth',\n",
       " 'AI',\n",
       " 'Robotics',\n",
       " 'Automation',\n",
       " 'Ro',\n",
       " 'Robotics',\n",
       " 'Automation',\n",
       " 'Ro',\n",
       " 'ArtificialIntelligence',\n",
       " 'REALITY',\n",
       " 'MachineLearning',\n",
       " 'BigData',\n",
       " 'Analytics',\n",
       " 'DataScien',\n",
       " 'MachineLearning',\n",
       " 'BigData',\n",
       " 'Analytics',\n",
       " 'DataScien',\n",
       " 'URL',\n",
       " 'python3',\n",
       " 'datatype',\n",
       " 'programming',\n",
       " 'coding',\n",
       " 'Python',\n",
       " 'Java',\n",
       " 'javascript',\n",
       " 'FEATURED',\n",
       " 'COURSES',\n",
       " 'Intelligence',\n",
       " 'Unity',\n",
       " 'artificialintelligence',\n",
       " 'Itamaraty',\n",
       " 'AI',\n",
       " 'cybersec',\n",
       " 'privacy',\n",
       " 'bigdata',\n",
       " 'behavioraleconomics',\n",
       " 'fintech',\n",
       " 'Blockchain',\n",
       " 'Artificial_Intelligence',\n",
       " 'Thegame23',\n",
       " 'Tyler',\n",
       " 'digilosofia',\n",
       " 'SwissCognitive',\n",
       " 'AINews',\n",
       " 'AI',\n",
       " 'Art',\n",
       " 'ArtificialIntelligence',\n",
       " 'ui',\n",
       " 'AI',\n",
       " 'Art',\n",
       " 'Artif',\n",
       " 'Artif',\n",
       " 'Artif',\n",
       " 'ArtificialIntelligence',\n",
       " 'Education',\n",
       " 'AI',\n",
       " 'edutech',\n",
       " 'fintech',\n",
       " 'AI',\n",
       " 'ArtificialIntelligence',\n",
       " 'AI',\n",
       " 'Technology',\n",
       " 'ArtificialIntellig',\n",
       " '100DaysOfCode',\n",
       " '100DaysOfMLCode',\n",
       " 'DEVCommunity',\n",
       " 'womenwhocode',\n",
       " 'ai',\n",
       " 'Artificia',\n",
       " 'ai',\n",
       " 'ArtificialIn',\n",
       " 'AI',\n",
       " 'Udemy',\n",
       " 'udemycoupon',\n",
       " 'ArtificialIntelligence',\n",
       " 'AI',\n",
       " 'DataScience',\n",
       " 'ML',\n",
       " 'DeepLearning',\n",
       " 'Tech',\n",
       " 'HR',\n",
       " 'Business',\n",
       " 'DL',\n",
       " 'DigitalTransformation',\n",
       " 'Artif',\n",
       " 'RaviVisvesvarayaSharadaPrasad',\n",
       " 'RT',\n",
       " 'RaviVisvesvarayaSharadaPrasad',\n",
       " 'RT',\n",
       " 'FEATURED',\n",
       " 'COURSES',\n",
       " 'Intelligence',\n",
       " 'Unity',\n",
       " 'artificialintelligence',\n",
       " 'MachineLearn',\n",
       " 'Infographic',\n",
       " 'MachineLearning',\n",
       " 'Python',\n",
       " 'NLP',\n",
       " 'Analytics',\n",
       " 'AI',\n",
       " 'datascience',\n",
       " 'ad',\n",
       " 'Artificial_Intelligence',\n",
       " 'Algorithm',\n",
       " 'TechJunkieNews',\n",
       " 'ArtificialIntelligence',\n",
       " 'AI',\n",
       " 'ArtificialIntelligence',\n",
       " 'Ronald_teaches_Artificial_Intelligence',\n",
       " 'AI',\n",
       " 'philosophical',\n",
       " 'machinelearning',\n",
       " 'intoAInews',\n",
       " 'FEATURED',\n",
       " 'COURSES',\n",
       " 'Intelligence',\n",
       " 'Unity',\n",
       " 'artificialintelligence',\n",
       " 'AIoT',\n",
       " 'IoT',\n",
       " 'BERT',\n",
       " 'MachineLearning',\n",
       " 'DataScience',\n",
       " '100DaysOf',\n",
       " 'ArtificialIntelligence',\n",
       " 'learning',\n",
       " 'machinelearning',\n",
       " 'cybertruck',\n",
       " 'Artificial_Intelligence',\n",
       " 'network',\n",
       " 'programmerlife',\n",
       " 'python3',\n",
       " 'datatype',\n",
       " 'programming',\n",
       " 'coding',\n",
       " 'Pytho',\n",
       " 'AnthonyBourdain',\n",
       " 'AI',\n",
       " 'artificialintelligence',\n",
       " 'Finperform',\n",
       " 'AI',\n",
       " 'ArtificialIntelligence',\n",
       " 'ArtificialIntellig',\n",
       " 'AI',\n",
       " 'Artificial_Intelligence',\n",
       " 'futureofw',\n",
       " 'MachineLearning',\n",
       " 'Artifici',\n",
       " 'Machi',\n",
       " 'ai',\n",
       " 'intoAInews',\n",
       " 'Arti',\n",
       " 'hcsm',\n",
       " 'socmed',\n",
       " 'TeachingandLearning',\n",
       " 'AI',\n",
       " 'RiseoftheRobots',\n",
       " 'AI',\n",
       " 'DeepLearning',\n",
       " 'Machine',\n",
       " 'MachineLearning',\n",
       " 'FEATURED',\n",
       " 'COURSES',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'ArtificialIntelligence',\n",
       " 'fintech',\n",
       " 'AI',\n",
       " 'MachineLearning',\n",
       " 'DeepLearning',\n",
       " 'technology',\n",
       " 'datascience',\n",
       " 'deeplearning',\n",
       " 'python',\n",
       " 'programming',\n",
       " 'tech',\n",
       " 'robotics',\n",
       " 'bigdata',\n",
       " 'coding',\n",
       " 'iot',\n",
       " 'computerscience',\n",
       " 'data',\n",
       " 'datascience',\n",
       " 'ad',\n",
       " 'artificialintelligence',\n",
       " 'artificialintelligencetechnology',\n",
       " 'ArtificialIntelligence',\n",
       " 'MachineLearning',\n",
       " 'pharmaceutical',\n",
       " 'AI',\n",
       " 'AI',\n",
       " 'G検定',\n",
       " 'Artificial_Intelligence',\n",
       " 'Standardisation',\n",
       " 'AI',\n",
       " 'health',\n",
       " 'research',\n",
       " 'ArtificialIntelligence',\n",
       " 'OvarianCancer',\n",
       " 'xAPI',\n",
       " 'dsc_Article',\n",
       " 'dsc_hash_Indhu44326',\n",
       " 'WebsiteTechNews',\n",
       " 'techarticle',\n",
       " 'techarticles',\n",
       " 'webarticle',\n",
       " 'webarticles',\n",
       " 'Calculus',\n",
       " 'DeepNeuralNetworks',\n",
       " 'ArtificialIntelligence',\n",
       " 'LinearRegression',\n",
       " 'CNNs',\n",
       " 'LinearAlgebra',\n",
       " 'DicisionForests',\n",
       " 'NLP',\n",
       " 'Caffe',\n",
       " 'ComputerVision',\n",
       " 'DataX',\n",
       " 'SmartCity',\n",
       " 'ArtificialIntelligence',\n",
       " 'AI',\n",
       " 'python3',\n",
       " 'datatype',\n",
       " 'programming',\n",
       " 'coding',\n",
       " 'Python',\n",
       " 'Java',\n",
       " 'javascript',\n",
       " 'cod',\n",
       " 'Art',\n",
       " 'ai',\n",
       " 'ml',\n",
       " 'dl',\n",
       " 'AI',\n",
       " 'ArtificialIntelligence',\n",
       " 'DL',\n",
       " 'DataScience',\n",
       " 'HealthTech',\n",
       " 'MedTech',\n",
       " 'BigData',\n",
       " 'MachineLearning',\n",
       " 'DevOps',\n",
       " 'SmartLiving',\n",
       " 'artificial',\n",
       " 'intelligence',\n",
       " 'DigitalTransformation',\n",
       " 'BusinessAgility',\n",
       " 'CX',\n",
       " 'UX',\n",
       " 'IoT',\n",
       " 'AI',\n",
       " 'TimeTracking',\n",
       " 'ContentResearch',\n",
       " 'BlogWriting',\n",
       " 'TheWebThisWeek',\n",
       " 'AI',\n",
       " 'IoT',\n",
       " 'BigDat',\n",
       " 'IoT',\n",
       " 'BigDat',\n",
       " 'DYOR',\n",
       " 'DPC',\n",
       " 'DAPPCENTS',\n",
       " 'DAPPDOLLAS',\n",
       " 'dsc_Article',\n",
       " 'dsc_hash_GauravSharma44326',\n",
       " 'Artificia',\n",
       " 'MachineLearning',\n",
       " '5G',\n",
       " 'DataScience',\n",
       " '1',\n",
       " 'AI',\n",
       " 'ArtificialIntelligence',\n",
       " 'AppliedAI',\n",
       " 'Facu',\n",
       " 'ArtificialIntelligence',\n",
       " 'ArtificialIntelligence',\n",
       " 'ArtificialIntelligence',\n",
       " 'AI',\n",
       " 'ai',\n",
       " 'intoAIne',\n",
       " 'ArtificialInt',\n",
       " 'book',\n",
       " 'xai',\n",
       " 'artificialintelligence',\n",
       " 'smart',\n",
       " 'city',\n",
       " 'ArtificialIntelligence',\n",
       " 'MachineLe',\n",
       " 'AI',\n",
       " 'UIDesign',\n",
       " 'targetedindividuals',\n",
       " 'AI',\n",
       " 'Artificial_Intelligence',\n",
       " 'IOT',\n",
       " 'machinelearning',\n",
       " 'artificialintelli',\n",
       " 'AI',\n",
       " 'ArtificialIntelligence',\n",
       " 'Houston',\n",
       " 'algorithms',\n",
       " 'artificialintelligence',\n",
       " 'ai',\n",
       " 'krs',\n",
       " 'searchengines',\n",
       " 'AI',\n",
       " 'Artificial',\n",
       " '100DaysOfCode',\n",
       " '100Days',\n",
       " '100DaysOfCode',\n",
       " '100Days',\n",
       " 'ArtificialIntelligence',\n",
       " 'ArtificialIntelligence',\n",
       " 'AI',\n",
       " 'Edge',\n",
       " 'Education',\n",
       " 'ArtificialIntelligence',\n",
       " 'AI',\n",
       " 'Edge',\n",
       " 'CyberSecurity',\n",
       " 'infosec',\n",
       " '100DaysOfCode',\n",
       " 'SmartCity',\n",
       " 'A',\n",
       " 'الذكاء_الاصطناعي',\n",
       " 'MachineLearning',\n",
       " 'Da',\n",
       " 'US',\n",
       " 'MachineLearning',\n",
       " 'Da',\n",
       " 'AI',\n",
       " 'Artificialintelligence',\n",
       " 'IoT',\n",
       " 'DeepLearning',\n",
       " 'DataScience',\n",
       " 'AI',\n",
       " 'ArtificialIntelligence',\n",
       " 'learning',\n",
       " 'machinelearning',\n",
       " 'execed',\n",
       " 'tekoäly',\n",
       " 'AI',\n",
       " 'pyt',\n",
       " 'Artific',\n",
       " 'Ho',\n",
       " 'AI',\n",
       " 'ABBx',\n",
       " 'AI',\n",
       " 'IA',\n",
       " 'artificialIntelligence',\n",
       " 'inteligenciaArtificial',\n",
       " 'AI',\n",
       " 'IA',\n",
       " 'artificialIntelligence',\n",
       " 'inteligenciaArtificial',\n",
       " 'ai',\n",
       " 'artificialintelligence',\n",
       " 'FullStack',\n",
       " 'python3',\n",
       " 'datatype',\n",
       " 'programming',\n",
       " 'coding',\n",
       " 'Python',\n",
       " 'Java',\n",
       " 'javascript',\n",
       " 'code',\n",
       " 'cod',\n",
       " 'FullStack',\n",
       " 'python3',\n",
       " 'datatype',\n",
       " 'programming',\n",
       " 'coding',\n",
       " 'Python',\n",
       " 'Java',\n",
       " 'javascript',\n",
       " 'code',\n",
       " 'cod',\n",
       " 'ArtificialIntelligence',\n",
       " 'AI',\n",
       " 'Robots',\n",
       " 'ArtificialIntelligence',\n",
       " 'AI',\n",
       " 'DYOR',\n",
       " 'DPC',\n",
       " 'DAPPCENTS',\n",
       " 'DAPPDOLLAS',\n",
       " 'MachineLearning',\n",
       " '5G',\n",
       " 'DataScience',\n",
       " 'MachineLearning',\n",
       " '5G',\n",
       " 'DataScience',\n",
       " 'technology',\n",
       " 'psychology',\n",
       " 'ai',\n",
       " 'artificialintelligence',\n",
       " 'johnmccarthy',\n",
       " 'ArtificialIntelligence',\n",
       " 'Health',\n",
       " 'technology',\n",
       " 'psychology',\n",
       " 'ai',\n",
       " 'artificialintelligence',\n",
       " 'johnmccarthy',\n",
       " 'technology',\n",
       " 'psychology',\n",
       " 'ai',\n",
       " 'artificialintelligence',\n",
       " 'johnmccarthy',\n",
       " 'artificial',\n",
       " 'intelligence',\n",
       " 'venous',\n",
       " 'thromb',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'automation',\n",
       " 'deep',\n",
       " 'robots',\n",
       " 'palantir',\n",
       " 'skynet',\n",
       " 'ArtificialIntelligence',\n",
       " 'ArtificialIntell',\n",
       " 'ArtificialIntell',\n",
       " 'ComicBookInvasion',\n",
       " 'Artificalintelligence',\n",
       " 'Boom',\n",
       " 'Future',\n",
       " 'Art',\n",
       " 'ArtificialIntelligence',\n",
       " 'ArtificialIntelligence',\n",
       " 'Bi',\n",
       " 'ArtificialIntelligence',\n",
       " 'AI',\n",
       " 'BigData',\n",
       " 'Business',\n",
       " 'DigitalTransformation',\n",
       " 'Analytics',\n",
       " 'DeepLearning',\n",
       " 'Algorithms',\n",
       " 'FEATURED',\n",
       " 'COURSES',\n",
       " 'Intelligence',\n",
       " 'Unity',\n",
       " 'artificialintelligence',\n",
       " 'ArtificialIntelligence',\n",
       " 'data',\n",
       " 'patient',\n",
       " 'AI',\n",
       " 'ONPASSIVE',\n",
       " 'ONPASS',\n",
       " 'artificial',\n",
       " 'artificialintelligence',\n",
       " 'ai',\n",
       " 'logo',\n",
       " 'LogoDesign',\n",
       " 'udemydeals',\n",
       " 'udemydiscounts',\n",
       " 'udemy100off',\n",
       " 'udemyfreecourse',\n",
       " 'udemyfree',\n",
       " 'FEATURED',\n",
       " 'COURSES',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'mwm',\n",
       " 'ArtificialIntelligence',\n",
       " 'AI',\n",
       " 'DataScience',\n",
       " '100DaysOfCode',\n",
       " 'ArtificialIntelligence',\n",
       " 'AI',\n",
       " 'DataScience',\n",
       " '100DaysOfCode',\n",
       " 'ai',\n",
       " 'ArtificialIntelligence',\n",
       " 'MachineLearning',\n",
       " 'DeepLearning',\n",
       " 'creativity',\n",
       " 'AI',\n",
       " 'ML',\n",
       " 'ArtificialIntelligence',\n",
       " 'ai',\n",
       " 'ArtificialIntelligence',\n",
       " 'MachineLearning',\n",
       " 'DeepLearning',\n",
       " 'research',\n",
       " 'ArtificialIntelligence',\n",
       " 'AI',\n",
       " 'marketing',\n",
       " 'businesss',\n",
       " 'branding',\n",
       " 'MachineLearning',\n",
       " 'MachineLearni',\n",
       " 'ArtificialIntelligence',\n",
       " 'fintech',\n",
       " 'AI',\n",
       " 'MachineLearning',\n",
       " 'DeepLe',\n",
       " 'ArtificialIntelligence',\n",
       " 'fintech',\n",
       " 'AI',\n",
       " 'MachineLearning',\n",
       " 'DeepLe',\n",
       " 'Pizza',\n",
       " 'AI',\n",
       " 'AI',\n",
       " 'ArtificialIntelligence',\n",
       " 'Ai',\n",
       " 'Britain',\n",
       " 'britishempire',\n",
       " 'Automation',\n",
       " 'Robotic',\n",
       " 'HR',\n",
       " 'Artificial',\n",
       " 'ArtificialIntelligence',\n",
       " 'fintech',\n",
       " 'AI',\n",
       " 'MachineLearning',\n",
       " 'DeepLe',\n",
       " 'AI',\n",
       " 'MachineLearning',\n",
       " 'DataS',\n",
       " 'MachineLearning',\n",
       " 'DataS',\n",
       " 'Art',\n",
       " 'Artificia',\n",
       " 'ArtificialIntelligence',\n",
       " 'BGI',\n",
       " 'MachineLea',\n",
       " 'MachineLea',\n",
       " 'machinelearning',\n",
       " 'datascience',\n",
       " 'bigdata',\n",
       " 'AI',\n",
       " 'artificialintelligence',\n",
       " 'ad',\n",
       " 'uap',\n",
       " 'ufo',\n",
       " 'ArtificialIntelligence',\n",
       " 'AI',\n",
       " 'AI',\n",
       " 'AutonomousVehicles',\n",
       " 'deeplearning',\n",
       " 'ArtificialIntelligence',\n",
       " 'ArtificialIntelligence',\n",
       " 'HealthTech',\n",
       " 'TechForGood',\n",
       " 'AIEYE',\n",
       " 'Podcast',\n",
       " 'Stocks',\n",
       " 'artificialintelligence',\n",
       " 'AI',\n",
       " 'Stoc',\n",
       " 'Artif',\n",
       " 'China',\n",
       " 'US',\n",
       " 'cannabis',\n",
       " 'hellomary',\n",
       " 'artificialintelligence',\n",
       " 'artificialintelligence',\n",
       " 'recreationalcannabis',\n",
       " 'cannabis',\n",
       " 'california',\n",
       " 'MachineLearning',\n",
       " '5G',\n",
       " 'DataS',\n",
       " 'chatbots',\n",
       " 'AI',\n",
       " 'energy',\n",
       " 'MWC2021',\n",
       " 'fintech',\n",
       " 'insurtech',\n",
       " 'AI',\n",
       " 'ArtificialIntelligence',\n",
       " 'VLSI',\n",
       " 'VLSIInstituteBanglore',\n",
       " 'ArtificialIntelligence',\n",
       " 'AI',\n",
       " 'ArtificialIntelligence',\n",
       " 'ArtificialIntelligence',\n",
       " 'IITDelhi',\n",
       " 'AI',\n",
       " 'Medicine',\n",
       " 'BioEthics',\n",
       " 'ArtificialIntelligence',\n",
       " 'AI',\n",
       " 'DataScience',\n",
       " '100Day',\n",
       " 'aiethics',\n",
       " 'aiforgood',\n",
       " 'aiandthelaw',\n",
       " 'ArtificialIntelligence',\n",
       " 'AI',\n",
       " 'DataScience',\n",
       " '100Day',\n",
       " 'MachineLearning',\n",
       " 'Data',\n",
       " 'AI',\n",
       " 'Blockchain',\n",
       " 'crypto',\n",
       " 'Arti',\n",
       " 'ArtificialIntelligence',\n",
       " 'AI',\n",
       " 'SMLearningFX',\n",
       " 'ArtificialIntellig',\n",
       " 'ArtificialIntellige',\n",
       " 'ArtificialIntelligence',\n",
       " 'ArtificialIntelligence',\n",
       " 'AI',\n",
       " 'DP',\n",
       " 'ML',\n",
       " 'Io',\n",
       " 'artificial',\n",
       " 'TechForGood',\n",
       " 'AI',\n",
       " 'ArtificialIntelligen',\n",
       " 'onlinereputationmanagement',\n",
       " 'DigitalTransformation',\n",
       " 'ArtificialIntelligence',\n",
       " 'udemy',\n",
       " 'DataScience',\n",
       " 'Artificia',\n",
       " 'artificialintelligence',\n",
       " 'health',\n",
       " 'mobility',\n",
       " 'industry40',\n",
       " 'cybersecurity',\n",
       " 'AI',\n",
       " 'ONPASSIVE',\n",
       " 'ONPASSIVE',\n",
       " 'ONPAS',\n",
       " 'Localization',\n",
       " 'ArtificialIntelligence',\n",
       " 'Analytics',\n",
       " 'Translation',\n",
       " 'Data',\n",
       " 'AUTOLY_IN',\n",
       " 'NeuralNetworks',\n",
       " 'Automotive',\n",
       " 'ArtificialIntelligence',\n",
       " 'AI',\n",
       " 'MachineLearning',\n",
       " 'DeepLearning',\n",
       " 'Emergin',\n",
       " 'dsc_Article',\n",
       " 'dsc_ha',\n",
       " 'MachineLearn',\n",
       " 'Arti',\n",
       " 'Arti',\n",
       " 'MachineLearn',\n",
       " 'ai',\n",
       " 'intoAInews',\n",
       " 'artificialintelligence',\n",
       " 'ai',\n",
       " 'ma',\n",
       " 'ai',\n",
       " 'intoAInews',\n",
       " 'AI',\n",
       " 'ML',\n",
       " 'DeepLearning',\n",
       " 'bigdata',\n",
       " 'learning',\n",
       " 'data',\n",
       " 'ArtificialIntelligence',\n",
       " 'AI',\n",
       " 'DataSc',\n",
       " 'MachineLearning',\n",
       " '5',\n",
       " 'artificial',\n",
       " 'Artif',\n",
       " 'AI',\n",
       " 'ML',\n",
       " 'Artif',\n",
       " 'ArtificialIntelligence',\n",
       " 'Tech',\n",
       " 'SAAS',\n",
       " 'SoftwareAsAservice',\n",
       " 'Localization',\n",
       " 'ArtificialIntelligence',\n",
       " 'Analytics',\n",
       " 'Tra',\n",
       " 'AI',\n",
       " 'cyber',\n",
       " 'Artificial_Intelligence',\n",
       " 'Artif',\n",
       " 'MachineLearning',\n",
       " 'BigData',\n",
       " 'Analytics',\n",
       " 'DataScien',\n",
       " 'AI',\n",
       " 'Häme',\n",
       " 'Hämeenlinna',\n",
       " 'Artificial_Intelligence',\n",
       " 'ArtificialIntelligence',\n",
       " 'MachineLearning',\n",
       " 'ArtificialIntelligence',\n",
       " 'Healthcare',\n",
       " 'HealthTech',\n",
       " 'AI',\n",
       " 'SpaceJamMovie',\n",
       " 'LeBronJames',\n",
       " 'programming',\n",
       " 'coding',\n",
       " 'Python',\n",
       " 'Java',\n",
       " 'javascript',\n",
       " 'code',\n",
       " 'coder',\n",
       " '100DaysOfCode',\n",
       " 'A',\n",
       " 'Arti',\n",
       " 'ArtificialIntelligence',\n",
       " 'AI',\n",
       " 'HealthTech',\n",
       " 'artificialintelligence',\n",
       " 'roboticsurgery',\n",
       " 'innovation',\n",
       " 'cybersecurity',\n",
       " 'AI',\n",
       " 'ArtificialIntelligence',\n",
       " 'AI',\n",
       " 'HealthTech',\n",
       " 'MachineLearning',\n",
       " 'AI',\n",
       " 'Security',\n",
       " 'Ink',\n",
       " 'CyberSecurity',\n",
       " '𝒟𝒾𝑒𝒷𝒪37',\n",
       " 'ArtificialIntelligence',\n",
       " 'AI',\n",
       " 'ai',\n",
       " 'ml',\n",
       " 'dl',\n",
       " 'SaudiArabia',\n",
       " 'MachineLearning',\n",
       " '5G',\n",
       " 'Da',\n",
       " 'MachineLearni',\n",
       " 'MachineLearni',\n",
       " 'AI',\n",
       " 'Art',\n",
       " 'ArtificialIntelligence',\n",
       " 'data',\n",
       " 'FEATURED',\n",
       " 'COURSES',\n",
       " 'Intelligence',\n",
       " 'Unity',\n",
       " 'artificialintelligence',\n",
       " 'AI',\n",
       " 'computergames',\n",
       " 'unity',\n",
       " 'programming',\n",
       " 'game',\n",
       " 'development',\n",
       " 'gamedevelopment',\n",
       " 'Houston',\n",
       " 'ArtificialIn',\n",
       " 'FMTNews',\n",
       " 'FMTLifestyle',\n",
       " 'ai',\n",
       " 'ArtificialIntel',\n",
       " 'AI',\n",
       " 'MachineLearning',\n",
       " 'AR',\n",
       " 'WUS2021',\n",
       " 'MachineLearning',\n",
       " 'DataSci',\n",
       " 'SEO',\n",
       " 'socialmedia',\n",
       " 'pyton',\n",
       " 'python',\n",
       " 'pythonic',\n",
       " 'ml',\n",
       " 'machinelearning',\n",
       " 'freecourses',\n",
       " 'mkt_art',\n",
       " 'PrograminLovers',\n",
       " 'ArtificialIntelligence',\n",
       " 'AI',\n",
       " 'Art',\n",
       " 'Artif',\n",
       " 'Technology',\n",
       " 'ArtificialIntelligence',\n",
       " 'AugmentedReality',\n",
       " '5G',\n",
       " 'AI',\n",
       " 'AR',\n",
       " 'HealthTech',\n",
       " 'journalism',\n",
       " 'AI',\n",
       " 'cybersecurity',\n",
       " 'Industry40',\n",
       " 'Data',\n",
       " 'AI',\n",
       " 'ArtificialIntelligence',\n",
       " 'oilandgas',\n",
       " 'oilgas',\n",
       " 'energy',\n",
       " 'offshore',\n",
       " 'oilfield',\n",
       " 'drilling',\n",
       " 'optimization',\n",
       " 'AUTOMATION',\n",
       " 'digitalization',\n",
       " 'BigData',\n",
       " 'NorthAmerica',\n",
       " 'Singapore',\n",
       " 'AI',\n",
       " 'Analyt',\n",
       " 'AI',\n",
       " 'mach',\n",
       " 'artificialintelligence',\n",
       " 'COVID19',\n",
       " 'Imperial',\n",
       " 'WEF',\n",
       " 'Salesforce',\n",
       " 'Sinovatio',\n",
       " 'FEATURED',\n",
       " 'COURSES',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'Algorand',\n",
       " 'AI',\n",
       " 'MachineLearning',\n",
       " 'DeepLearning',\n",
       " 'DataSc',\n",
       " 'ai',\n",
       " 'ArtificialIntelligence',\n",
       " 'Machin',\n",
       " 'ai',\n",
       " 'ArtificialIntelligence',\n",
       " 'Machin',\n",
       " 'AI',\n",
       " 'artificialintelligence',\n",
       " 'Finperform',\n",
       " 'FLEETINSURBROKR',\n",
       " 'SRSBROKERS',\n",
       " 'learning',\n",
       " 'Intelligence',\n",
       " 'MIT',\n",
       " 'Technology',\n",
       " 'AI',\n",
       " 'ArtificialIntelligence',\n",
       " 'payments',\n",
       " 'fintech',\n",
       " 'pa',\n",
       " 'NIHData',\n",
       " 'DiversityinSTEM',\n",
       " 'healthdisparities',\n",
       " 'AI',\n",
       " 'ML',\n",
       " 'ArtificialIntelligence',\n",
       " 'ai',\n",
       " 'Arti',\n",
       " 'AI',\n",
       " 'taekookau',\n",
       " 'machinelearning',\n",
       " 'artificialintelligence',\n",
       " 'deeplearning',\n",
       " 'datascience',\n",
       " 'ArtificialIn',\n",
       " 'ArtificialIn',\n",
       " 'ArtificialIn',\n",
       " 'ArtificialInte',\n",
       " 'FBI',\n",
       " 'CYBERTORTURE',\n",
       " 'nanotechnology',\n",
       " 'Vaccines',\n",
       " 'BIOWEAPONS',\n",
       " 'HumanTrafficking',\n",
       " 'ArtificialInte',\n",
       " 'MachineLearning',\n",
       " 'learning',\n",
       " 'MachineLearning',\n",
       " 'learning',\n",
       " 'MachineLearning',\n",
       " 'AI',\n",
       " 'Retail',\n",
       " 'fintech',\n",
       " 'education',\n",
       " 'Insurtech',\n",
       " 'martech',\n",
       " 'BigData',\n",
       " 'artificialintelligence',\n",
       " 'AI',\n",
       " 'Datawarehouse',\n",
       " 'ArtificialIntellig',\n",
       " 'MachineLearning',\n",
       " '5G',\n",
       " 'DataScience',\n",
       " '100DaysOf',\n",
       " 'pyt',\n",
       " 'DataScience',\n",
       " 'webinar',\n",
       " 'WUS2021',\n",
       " 'ai',\n",
       " 'ArtificialIntelligence',\n",
       " 'hype',\n",
       " 'MachineLearning',\n",
       " 'fintech',\n",
       " 'AI',\n",
       " 'ML',\n",
       " 'DataScience',\n",
       " 'ArtificialIntelligence',\n",
       " 'Neuromorphic',\n",
       " 'Blockchain',\n",
       " 'InternetOfBehaviors',\n",
       " 'Coursera',\n",
       " 'NaturalLanguageProcessing',\n",
       " 'Metaverse',\n",
       " 'Chatbot',\n",
       " 'Numpy',\n",
       " 'VirtualReality',\n",
       " 'AI',\n",
       " 'cybersecurity',\n",
       " 'MachineLearnin',\n",
       " 'ai',\n",
       " 'blockchain',\n",
       " 'arificialinterlligence',\n",
       " 'ai',\n",
       " 'blockchain',\n",
       " 'arificialinterlligence',\n",
       " 'artificialintellige',\n",
       " 'ArtificialIntelligence',\n",
       " 'ArtificialIntelligence',\n",
       " 'ai',\n",
       " 'innova',\n",
       " 'AI',\n",
       " 'Artificialintelligence',\n",
       " 'ML',\n",
       " 'MachineLearning',\n",
       " 'France',\n",
       " 'FEATURED',\n",
       " 'COURSES',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'artificialintelligencenow',\n",
       " 'retailtech',\n",
       " 'CIOs',\n",
       " 'Arti',\n",
       " ...]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_hashtag()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>AuthorLocation</th>\n",
       "      <th>CreatedAt</th>\n",
       "      <th>RetweetCount</th>\n",
       "      <th>TweetLanguage</th>\n",
       "      <th>TweetText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1707</th>\n",
       "      <td>1328975536883824384</td>\n",
       "      <td>Amsterdam, Netherland</td>\n",
       "      <td>2023-12-06T11:35:05Z</td>\n",
       "      <td>10</td>\n",
       "      <td>en</td>\n",
       "      <td>I'm very happy, i finally fixed my issue with ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id         AuthorLocation             CreatedAt  \\\n",
       "1707  1328975536883824384  Amsterdam, Netherland  2023-12-06T11:35:05Z   \n",
       "\n",
       "      RetweetCount TweetLanguage  \\\n",
       "1707            10            en   \n",
       "\n",
       "                                              TweetText  \n",
       "1707  I'm very happy, i finally fixed my issue with ...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tweet_hashtag(\"InPoDa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet id : 1328975536883824267\n",
      "Author Location : Amsterdam, Netherland \n",
      "Tweet Creation : 2023-12-06T11:35:05Z \n",
      "Number of Retweets : 10 \n",
      "Tweet Language : en \n",
      "Tweet Text : I'm very happy, i finally fixed my issue with saving the incoming data @Ahmad  ! #code #debug #InPoDa #projet\n"
     ]
    }
   ],
   "source": [
    "print(tweets[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_mentionned(1418705513660010496)        # à corriger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tweet_hashtag(\"MachineLearning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tweet_mention(\"nigewillson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_mentionned(1415291886860967936)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>AuthorLocation</th>\n",
       "      <th>CreatedAt</th>\n",
       "      <th>RetweetCount</th>\n",
       "      <th>TweetLanguage</th>\n",
       "      <th>TweetText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1703</th>\n",
       "      <td>1421424066305605632</td>\n",
       "      <td></td>\n",
       "      <td>2021-07-31T10:54:40Z</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>Iowa State part of U.S. National Science Found...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1704</th>\n",
       "      <td>1421423882427371520</td>\n",
       "      <td>127.0.0.1</td>\n",
       "      <td>2021-07-31T10:53:57Z</td>\n",
       "      <td>17</td>\n",
       "      <td>en</td>\n",
       "      <td>RT @intellimetri: Human Assisted #ArtificialIn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1705</th>\n",
       "      <td>1421423971858149376</td>\n",
       "      <td>Singapore, Singapore</td>\n",
       "      <td>2021-07-31T10:54:18Z</td>\n",
       "      <td>12</td>\n",
       "      <td>en</td>\n",
       "      <td>RT @IainLJBrown: Artificial Intelligence learn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1706</th>\n",
       "      <td>1421423964845395968</td>\n",
       "      <td>Torremolinos, España</td>\n",
       "      <td>2021-07-31T10:54:16Z</td>\n",
       "      <td>17</td>\n",
       "      <td>en</td>\n",
       "      <td>RT @marcusborba: Artificial Intelligence May F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1707</th>\n",
       "      <td>1328975536883824384</td>\n",
       "      <td>Amsterdam, Netherland</td>\n",
       "      <td>2023-12-06T11:35:05Z</td>\n",
       "      <td>10</td>\n",
       "      <td>en</td>\n",
       "      <td>I'm very happy, i finally fixed my issue with ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id         AuthorLocation             CreatedAt  \\\n",
       "1703  1421424066305605632                         2021-07-31T10:54:40Z   \n",
       "1704  1421423882427371520              127.0.0.1  2021-07-31T10:53:57Z   \n",
       "1705  1421423971858149376   Singapore, Singapore  2021-07-31T10:54:18Z   \n",
       "1706  1421423964845395968   Torremolinos, España  2021-07-31T10:54:16Z   \n",
       "1707  1328975536883824384  Amsterdam, Netherland  2023-12-06T11:35:05Z   \n",
       "\n",
       "      RetweetCount TweetLanguage  \\\n",
       "1703             0            en   \n",
       "1704            17            en   \n",
       "1705            12            en   \n",
       "1706            17            en   \n",
       "1707            10            en   \n",
       "\n",
       "                                              TweetText  \n",
       "1703  Iowa State part of U.S. National Science Found...  \n",
       "1704  RT @intellimetri: Human Assisted #ArtificialIn...  \n",
       "1705  RT @IainLJBrown: Artificial Intelligence learn...  \n",
       "1706  RT @marcusborba: Artificial Intelligence May F...  \n",
       "1707  I'm very happy, i finally fixed my issue with ...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_hashtag(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'AI': 214, 'ArtificialIntelligence': 208, 'MachineLearning': 86}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test for Top k hashtags\n",
    "all_hashtag()\n",
    "top_hashtag(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test for Top k users\n",
    "all_users()\n",
    "top_users(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test for Top k mentions\n",
    "all_mentions()\n",
    "top_mention(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tweet_hashtag(\"DataScience\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tweet_mention(\"SpirosMargaris\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_hashtag()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_specified_hashtag(\"FEATURED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_mentionned(1415291886860967936)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tweet_hashtag(\"machine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets[0].get_author()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'En été il fait très chaud , par contre en hiver il fait super froid '"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_cleaning(\"En été il fait très chaud 🌞, par contre en hiver il fait super froid 🥶\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
